{
  "hash": "d1f467f84f7d5aa8b248c3e1db647fc7",
  "result": {
    "markdown": "---\ntitle: \"Claim Estimation\"\nsubtitle: \"An Auto Insurance Example\"\nauthor: \"Zach Palmore\"\ndate: \"2022-08-14\"\ncategories: [predictive, modeling, data science]\nimage: \"image.jpg\"\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-link: true\n    highlight-style: pygments\n    html-math-method: katex\n    df-print: paged\n    cache: true\n    theme:\n      light: flatly\n      dark: darkly\n---\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell hash='index_cache/html/load-pkgs_52e43ed26d7d86859723d6a32eef76a5'}\n\n:::\n\n\n## The Challenge\n\nA key part of insurance is charging each customer the appropriate price for the risk they represent.\n\nThe challenge is knowing what is most likely to happen before it occurs. If we have confidence in what could occur, then we may better manage our risk. Data science offers a solution to this challenge. Developing advanced computational models with the capacity to crunch high volume data allows us to calculate probabilities of risk for many individuals at scale.\n\nThe business need is to predict the probability that a person will submit a claim and then estimate that claim amount. Multiple linear regression and binary logistic regression models were built to answer these questions. We explore, analyze and model with a data set containing records of customer behavior at an auto insurance company. A table with a selection of five variables that represent behavioral characteristics from customer records is shown below with a brief description of each for reference.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_45e82e2b3157b51263de1396a977a208'}\n\n```{.r .cell-code}\n# short descriptions of variables as table from matrix\nvardesc <- data.frame(matrix(c(\n'TARGET_FLAG',\t'Was a claim submitted? 1 = Yes, 0 = No',\n'TARGET_AMT',\t'Estimated amount of claim',\n'CLM_FREQ',\t'Number of claims filed in past five years',\n'MVR_PTS',\t'Motor vehicle inspection points',\n'TRAVETIME',\t'Distance to work in minutes'\n),  byrow = TRUE, ncol = 2))\ncolnames(vardesc) <- c('Variable', 'Description')\nkbl(vardesc, booktabs = T, caption = \"Variable Descriptions\") %>%\n  kable_styling(latex_options = c(\"striped\", \"HOLD_position\"), full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Variable Descriptions</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:left;\"> Description </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> TARGET_FLAG </td>\n   <td style=\"text-align:left;\"> Was a claim submitted? 1 = Yes, 0 = No </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TARGET_AMT </td>\n   <td style=\"text-align:left;\"> Estimated amount of claim </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> CLM_FREQ </td>\n   <td style=\"text-align:left;\"> Number of claims filed in past five years </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> MVR_PTS </td>\n   <td style=\"text-align:left;\"> Motor vehicle inspection points </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRAVETIME </td>\n   <td style=\"text-align:left;\"> Distance to work in minutes </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Data Prep\n\nThere are over 8000 records in this data set, with 26 variables in each record. We begin by loading in the data and exploring.\n\nWhen exploring we look for missing values and abnormalities and try to find patterns in the records. We calculate some descriptive and inferential statistics that show the characteristics present in the data. These statistics inform us if imputations, transformations, or other adjustments are needed. For example, this violin plot with a box plot inlay, provides a wealth of information.\n\n\n\n\n::: {.cell hash='index_cache/html/explore-violin-plot_1466e4ab1bc5bf47217cccb6104a6f0d'}\n\n```{.r .cell-code  code-summary=\"Kernel Density Estimation & Outliers\"}\ntdata %>% \n  select_if(is.numeric) %>% \n  gather() %>% \n  ggplot(aes(value, key)) +\n  facet_wrap(~ key, scales = \"free\") +\n  geom_violin(aes(color = key, alpha = 1)) + \n  geom_boxplot(aes(fill = key, alpha = .5), notch = TRUE, size = .1, lty = 3) +  \n  stat_summary(fun.y = mean, geom = \"point\",\n               shape = 8, size = 1.5, color = \"#000000\") + \n  theme_minimal() + \n  theme(axis.text = element_blank(), \n        axis.title = element_blank(), \n        legend.position = \"none\", plot.title = element_text(hjust = 0.5)) + \n  labs(title = \"Kernel Density Estimation & Outliers\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/explore-violin-plot-1.png){width=672}\n:::\n:::\n\n\nPerhaps one of the easiest things to spot in this plot are outliers, shown as grey dots on the left and right sides of the variables. These points are located far from where the rest of the data is, and there are so many that some dots appear solid black due to repeated grey dots plotted in the same spot. Our target amount, the value we intend to predict, is a great example of a distribution with a lot of outliers. These points give a good idea of what 'normal' is for each variable but this plot offers some more.\n\nIn this plot the asterisk near the center of each boxplot is the median of the distribution for all records that contain the variable named, however, what exactly the median is less important than where it lies within the distribution. The top and bottom edges (the curvy colored lines) of the violin plot use the non-parametric method kernel density estimation (KDE) to smoothly estimate the probability of a value occurring anywhere along its range. Here again, we already notice problems with our target amount. Although not every variable follows this pattern. For these reasons, we need to be careful about how we handle this data before making any predictions.\n\nAnother method used to explore and prepare the data is a correlation plot. These examine the strength of relationships between variables, whether they are positive or negative, and how they compare to one another. We take a look at some selected variables in hopes that they confirm some expectations.\n\n\n::: {.cell hash='index_cache/html/explore-correlation-plot_b740cf143a382e2c6ff88c02f903ed0f'}\n\n```{.r .cell-code  code-summary=\"Correlation Plot\"}\ntdata %>%\n  select_if(is.numeric) %>% \n  cor() %>% \n  ggcorrplot(method = \"circle\", type=\"upper\", \n             ggtheme = ggplot2::theme_minimal, legend.title = \"Influence\") + coord_flip() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/explore-correlation-plot-1.png){width=672}\n:::\n:::\n\n\nIf we are trying to predict the amount of a claim and we have a true or false variable indicating the presence or absences of claim submission (TARGET_FLAG) and the claim amount (TARGET_AMT), shouldn't we expect the two to be correlated? I would hope so, given that, when an individual does not file a claim, the resultant claim amount is 0. We notice this in the big red circle towards the bottom left of the screen. This shows a strong positive correlation between the amount of a claim and presence of a claim. From this correlation plot we start to confirm these expectations and validate some conventional auto insurance knowledge.\n\nThese demonstrate only two ways to look at data before model building. However, to ensure that a model functions in the real world, a multitude of exploratory methods should be used to fully understand the data. To keep it brief, the data is split 70-30 into training and testing data sets, then cleaned up with using the multiple imputation by chained equations (MICE) method, perform a Yeo-Johnson transformation, and adjust other points as necessary to make the non-normal predictor appear normal enough for prediction. A quick look at the imputed summary statistics is shown for four numeric variables as a reference.\n\n\n\n\n::: {.cell hash='index_cache/html/prep-imputed-statistics-table_ff5c2f71fb8a1689d623b4bf60d91387'}\n\n```{.r .cell-code  code-summary=\"Imputed Summary Statistics\"}\nimputed.stats.table <- data.frame(matrix(c(0,29707,54028,61469,83304,367030, \n         0,0,161160,155225,233352,885282,\n         1500,9280,14440,15710,20850,69740,\n         0,0,0,4037,4636,57037), ncol = 4, byrow = F)) \nnames(imputed.stats.table) <- c(\"Income\", \"Home Value\", \n                                \"Bluebook Value\", \"Old Claims\")\nimputed.stats.table <- imputed.stats.table %>% \n  mutate(Statistic = c(\"Min\", \"1st Quartile\", \"Median\", \n                       \"Mean\", \"3rd Qartile\", \"Max\")) %>%\n  dplyr::select(\"Statistic\", \"Income\", \"Home Value\", \n                \"Bluebook Value\", \"Old Claims\")\nkbl(imputed.stats.table,\n    booktabs = T,\n    caption = \"Imputed Summary Statistics\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"),\n                full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Imputed Summary Statistics</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Statistic </th>\n   <th style=\"text-align:right;\"> Income </th>\n   <th style=\"text-align:right;\"> Home Value </th>\n   <th style=\"text-align:right;\"> Bluebook Value </th>\n   <th style=\"text-align:right;\"> Old Claims </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Min </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1500 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 1st Quartile </td>\n   <td style=\"text-align:right;\"> 29707 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 9280 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Median </td>\n   <td style=\"text-align:right;\"> 54028 </td>\n   <td style=\"text-align:right;\"> 161160 </td>\n   <td style=\"text-align:right;\"> 14440 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mean </td>\n   <td style=\"text-align:right;\"> 61469 </td>\n   <td style=\"text-align:right;\"> 155225 </td>\n   <td style=\"text-align:right;\"> 15710 </td>\n   <td style=\"text-align:right;\"> 4037 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3rd Qartile </td>\n   <td style=\"text-align:right;\"> 83304 </td>\n   <td style=\"text-align:right;\"> 233352 </td>\n   <td style=\"text-align:right;\"> 20850 </td>\n   <td style=\"text-align:right;\"> 4636 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Max </td>\n   <td style=\"text-align:right;\"> 367030 </td>\n   <td style=\"text-align:right;\"> 885282 </td>\n   <td style=\"text-align:right;\"> 69740 </td>\n   <td style=\"text-align:right;\"> 57037 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n## Model Building\n\nOur objective was to build multiple linear regression and binomial logistic regression models to predict the amount of auto insurance claim. We explored, analyzed, and prepared the data as best we could in an attempt to improve the predictive outcome. The manner in which these were built is detailed in the Caret Model code chunk.\n\n\n::: {.cell hash='index_cache/html/model-builds_9cd48fd09a1354965688ce130262b173'}\n\n```{.r .cell-code  code-summary=\"Caret Models\"}\n# Model 1: Establish Baseline\n# This models uses only previous accident as a predictor\nmodel1 <- glm(TARGET_FLAG ~ previous_accident, \n              family = binomial(link = \"logit\"), train)\n# Model 2: Experimentally Determine Best Features by Hand\n# These features were selected by alpha level and intuition\nmodel2 <- glm(TARGET_FLAG ~ previous_accident + \n                city + young + clean_rec + \n                educated, family = binomial(link = \"logit\"), train)\n# Model 3: Add Recommended Risk Predictors from III\n# This model takes another step towards improving accuracy \nmodel3 <- glm(TARGET_FLAG ~ previous_accident + \n                city + mstatus + income.values + \n                sex + car_use + educated + KIDSDRIV + \n                revoked, family = binomial(link = \"logit\"), \n              train)\n# Model 4: All in One\n# Examine results with all variables included, what worked?\nmodel4 <- lm(target_amt ~ ., train) \n# Model 5: Linear Regression with Dollar Estimators\n# This model leans heavy on the variables with specific dollar figures\nmodel5 <- lm(target_amt ~ income.values +\n               home.values + bluebook.values + \n               oldclaim.values + avg_claim, \n             train) \n# Model 6: Multidirectional StepAIC Regression\n# This uses a Stepwise Akaike Information Criteria to evaluate \n# and select predictors in the model with some special data prep\nmodel6 <- lm(target_amt ~ . -TARGET_AMT -TARGET_FLAG, train) \npm <- stepAIC(model6, trace = F, direction = \"both\")\n```\n:::\n\n\nAnother model wherein everything but the kitchen sink was thrown at it (aptly known as the kitchen sink model), gave us insights into which variables were significant to use and what their effect on the model would probably be. Of course, with a model that contains over 30 variables, there is room for some complex interactions to occur. We rely on our exploration and analysis to guide us in the creation of additional models alongside the results from the kitchen sink model, historical model, and conventional wisdom from the auto insurance domain.\n\nSince we humans tend to poorly judge relationships represented as mathematical operations, a stepwise AIC model was created to do a lot of work for us. This model performs a check by cycling through the variables both forwards and backwards to pick the variables that are most likely to improve the predictive capacity of the model. The AIC just stands for Akaike Information Criterion which is an estimator of prediction error. In this model, when stepping (or cycling) through variables, we are using this criterion to select variables that reduce the amount of error present in the model. Ideally, this will improve model quality and output.\n\nWe finish with some general predictions of each model type. We created a historical model, kitchen sink model, a multidirectional stepwiseAIC, backward stepwiseAIC, high risk predictor model, and a conventional wisdom model using information from the Insurance Information Institute (III). These will be put to the test in the model selection process. Which one do you think will perform best?\n\n\n\n\n\n## Model Selection\n\nTo standardize the process of model selection, a function is created wherein all statistics are computed the same way. It begins by bringing in the holdout data we created in the data prep section. This is named the test data. With this we evaluate how accurately the model predicted the result. We then compute a confusion matrix which contains the rates of false positives, true positives, false negatives, and true negatives and estimate model specificity, sensitivity, precision, and recall with those values. These combined measures let us find the F1 score, and from them we can create a receiver operating characteristic (ROC) plot and find the area under the curve (AUC). These provide details about the accuracy and real-world effectiveness of a model.\n\n\n\n\n\nAs a quick reference, we show the results from one of the best models, that of the multidirectional stepwiseAIC. The receiver operating characteristic curve is plotted alongside text containing the accuracy, its bounds, how precise and sensitive it is as well as multiple significance values including McNemars p-value and an accuracy p-value. Each model went through this evaluation process.\n\n\n::: {.cell hash='index_cache/html/model-selection-model6-summary_f6acdc174812c2b6c040a9c09e3e56ca'}\n\n```{.r .cell-code  code-summary=\"Model Summary\"}\n# Create Function to Evaluate All Models\nmodstat <- function(model, test, \n                    target = \"TARGET_FLAG\", threshold = 0.5){\n  \n  # test model using predictions with test data\n  test$new <- ifelse(predict.glm(\n    model, test, \"response\") >= threshold, 1, 0) \n    \n    # create confusion matrix with stats\n    # shows true positive, false positive, and their inverse\n    cm <- confusionMatrix(factor(test$new), \n                          factor(test[[target]]), \"1\")\n    \n    # Organize information into data frame\n    df <- data.frame(obs = test$TARGET_FLAG, \n                     predicted = test$new, \n                     probs = predict(model, test))\n  \n  # Calculate performance and significance values\n  Pscores <- prediction(df$probs, \n                        df$obs)\n  \n  # AUC = \"Area Under the Curve\" \n  AUC <- performance(Pscores, \n                     measure = \"auc\")@y.values[[1]]\n    pscores <- performance(Pscores, \n                           \"tpr\", \"fpr\")\n  \n  # Plot the scores of true positive/ false positive\n    # This is a receiver operating characteristic (ROC) curve \n  plot(pscores,main=\"ROC Curve\", \n       sub = paste0(\"AUC: \", \n                    round(AUC, 3)))\n  \n  # Extract the F1 score \n    # place it below the plot for each model when run\n  results <- paste(cat(\"F1 = \", \n                       cm$byClass[7], \" \"), cm)\n  \n  # Output results with a ROC curve and all scores \n  return(results)\n}\n\n# Calculate and show ONLY model 6 for quick reference\nmodstat(model6, test)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/model-selection-model6-summary-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nF1 =  0.4838057  \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \" 1\"                                                                                                                                                                                                                                                                                                                                                                                             \n[2] \" c(1699, 113, 397, 239)\"                                                                                                                                                                                                                                                                                                                                                                        \n[3] \" c(Accuracy = 0.791666666666667, Kappa = 0.36653677545056, AccuracyLower = 0.775030346732191, AccuracyUpper = 0.807602177444679, AccuracyNull = 0.740196078431373, AccuracyPValue = 1.62575683811825e-09, McnemarPValue = 5.02353275353728e-36)\"                                                                                                                                                \n[4] \" c(Sensitivity = 0.375786163522013, Specificity = 0.937637969094923, `Pos Pred Value` = 0.678977272727273, `Neg Pred Value` = 0.810591603053435, Precision = 0.678977272727273, Recall = 0.375786163522013, F1 = 0.483805668016194, Prevalence = 0.259803921568627, `Detection Rate` = 0.0976307189542484, `Detection Prevalence` = 0.143790849673203, `Balanced Accuracy` = 0.656712066308468)\"\n[5] \" sens_spec\"                                                                                                                                                                                                                                                                                                                                                                                     \n[6] \" list()\"                                                                                                                                                                                                                                                                                                                                                                                        \n```\n:::\n:::\n\n\n## Conclusion\n\nRisk varies widely from customer to customer, and a deep understanding of different risk factors helps predict the likelihood and cost of insurance claims. Many factors contribute to the frequency and severity of car accidents including how, where and under what conditions people drive, as well as what they are driving. We developed 6 models. Half of these were multiple linear regression models and the other half were binomial logistic regression. Both have their benefits in the right context.\n\n\n::: {.cell hash='index_cache/html/conclusion-model-comparison_f99809853813b3e1d735825179943b9a'}\n\n```{.r .cell-code  code-summary=\"Comparison Table\"}\nmod.stats.table <- data.frame(matrix(c(\n         \"Model 1\", 0.722, 0.757, 0.5, .01, \n         \"Model 2\", 0.732, 0.767, 0.58, 0.333,\n         \"Model 3\", 0.754, 0.788, 0.625, 0.422,\n         \"Model 4\", 0.998, 0.999, 0.999, 0.999, \n         \"Model 5\", 0.719, 0.753, 0.514, .090,\n         \"Model 6\", 0.775, 0.808, 0.657, 0.484),\n         nrow = 6, byrow = T))\ncolnames(mod.stats.table) <- c(\"ID\", \"Lower Bound\", \"Upper Bound\", \n                               \"Balanced Accuracy\", \"F1 Score\")\nmod.stats.table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"ID\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Lower Bound\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Upper Bound\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Balanced Accuracy\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"F1 Score\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Model 1\",\"2\":\"0.722\",\"3\":\"0.757\",\"4\":\"0.5\",\"5\":\"0.01\"},{\"1\":\"Model 2\",\"2\":\"0.732\",\"3\":\"0.767\",\"4\":\"0.58\",\"5\":\"0.333\"},{\"1\":\"Model 3\",\"2\":\"0.754\",\"3\":\"0.788\",\"4\":\"0.625\",\"5\":\"0.422\"},{\"1\":\"Model 4\",\"2\":\"0.998\",\"3\":\"0.999\",\"4\":\"0.999\",\"5\":\"0.999\"},{\"1\":\"Model 5\",\"2\":\"0.719\",\"3\":\"0.753\",\"4\":\"0.514\",\"5\":\"0.09\"},{\"1\":\"Model 6\",\"2\":\"0.775\",\"3\":\"0.808\",\"4\":\"0.657\",\"5\":\"0.484\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWith an accuracy between 78 - 81%, the multidirectional stepwiseAIC model wins the contest between these two model types. It was also the most useful real-world model with a balanced accuracy at 65.7%. Its F1 score was 0.484, indicating the relationship between precision (how well it predicts true positives) and recall (ratio of correct positives in the predictions) is better than any other method of modeling.\n\nIn this table we reviewed the model's lower and upper accuracy bounds, its balanced accuracy, and F1 scores. The results show Model 3, our other stepwiseAIC, is the runner up. Model 4 is the only model that appears to have been too effective, and is not realistic for a variety of reasons. Perhaps the most important being over-fitting.\n\nOf these factors in prediction, balanced accuracy is likely the best criteria to judge the models on in this scenario. This is because it finds arithmetic mean of sensitivity and specificity which tends to represent imbalanced data better than accuracy alone. Since our data set was highly imbalanced and the target class of claim amount appeared much less than the non-target class, this accuracy estimate helps balance expectations.\n\nOf course, these predictions could be improved. When building models, it may be a good idea to perform some feature engineering to better isolate the riskiest and least risky customers. Other model types may also offer new insights.\n\nFor more, view the [full report](https://github.com/palmorezm/misc/blob/master/DS2_Share) on my GitHub page.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}