{
  "hash": "42f844bed2bf2ad4dd33731007a939b0",
  "result": {
    "markdown": "---\ntitle: \"Loan Approval\"\nsubtitle: \"A Credit Risk Assessment for Lenders\"\nauthor: \"Zach Palmore\"\ndate: \"2022-08-28\"\ncategories: [predictive, modeling, data science]\nimage: \"transparent_moneytree.png\"\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-link: true\n    highlight-style: pygments\n    html-math-method: katex\n    df-print: paged\n    cache: true\n    theme:\n      light: flatly\n      dark: darkly\n---\n\n\n------------------------------------------------------------------------\n\n\n\n\n\nThe main source of income of lenders stems from their credit line. Can it be improved?\n\nTo see the full report and source code, [visit my Github site](https://github.com/palmorezm/showcase/tree/master/posts/Loan%20Assessment).\n\n# Challenge\n\nWhen applying for a loan, banks and lenders use an individual's credit and other factors to determine the probability of repayment. Here, a predictive model is developed with study data that details how complex factors interact to determine the approval outcome for each individual. This method could be applied to any banks or lenders looking to lower the risk of default and loss in their portfolio to improve their institutional line of credit.\n\nIn this challenge we will develop models that allow us to predict whether a loan is approved given certain indicators. Models will include linear discriminant analysis, K-nearest neighbor, decision trees, and random forest algorithms and we will assess which performs best at predicting loan approval status through performance statistics.\n\n# Approach\n\nFor this challenge, we begin with data exploration to understand the relationships our target variable 'Loan_Status' will have with our indicator variables and the variables' relationships to each other. This allows us to determine the steps necessary to set up for model development. Once we have an understanding of these variables we use that knowledge to prepare the data. We handle missing values, subset, train and split the data 75/25 so that we may better extract information when modeling. Then, we build the models and predict with the testing dataset.\n\nWe focus on prediction accuracy when assessing the models but consider a host of performance statistics and real-world applications to determine which model is best.\n\nWe will use 'r' for data modeling. All packages used for data exploration, visualization, preparation and modeling are listed in Code Appendix.\n\n\n\n\n\n# Data Exploration\n\n## Data Characteristics\n\nThere are 614 observations of 12 variables. Each observation is an applicant's application for a loan with its corresponding variables of interest. Below is the description of the variables of interest in the data set.\n\n| VARIABLE NAME     | DESCRIPTION                                   |\n|-------------------|-----------------------------------------------|\n| Loan_ID           | Unique Loan ID                                |\n| Gender            | Male/ Female                                  |\n| Married           | Applicant married (Y/N)                       |\n| Dependents        | Number of dependents                          |\n| Education         | Applicant Education (Graduate/ Undergraduate) |\n| Self_Employed     | Self employed (Y/N)                           |\n| ApplicantIncome   | Applicant income                              |\n| CoapplicantIncome | Coapplicant income                            |\n| LoanAmount        | Loan amount in thousands                      |\n| Loan_Amount_Term  | Term of loan in months                        |\n| Credit_History    | credit history meets guidelines               |\n| Property_Area     | Urban/ Semi Urban/ Rural                      |\n| Loan_Status       | Loan approved (Y/N)                           |\n\nThere are four numeric variables represented by loan amount, loan amount term, applicant and co-applicant income. Several of these variables appear to be factors with specific levels but are not coded as such. For example, Gender, Married, Dependents, Education, Self_Employed, Property_Area, Credit_History, and Loan_Status are character strings. We will need to fix this if we are to make use of them.\n\n\n::: {.cell hash='LendingApproval_cache/html/data_69883904cd8ed48361e825b0fadd67f9'}\n\n```{.r .cell-code}\n# read data, change blank to NA and and remove loan_id\nloan_data <- read.csv('https://raw.githubusercontent.com/amit-kapoor/Data622Group2/main/Loan_approval.csv') %>% \n  na_if(\"\") %>%\n  dplyr::select(-1)\n\n# categorical columns as factors\nloan_data <- loan_data %>% \n  mutate(Gender=as.factor(Gender),\n         Married=as.factor(Married),\n         Dependents=as.factor(Dependents),\n         Education=as.factor(Education),\n         Self_Employed=as.factor(Self_Employed),\n         Property_Area=as.factor(Property_Area),\n         Credit_History=as.factor(Credit_History),\n         Loan_Status=as.factor(Loan_Status))\n```\n:::\n\n\n## Data summary\n\nBelow is a summary of the loan approval dataset. For this process we have already adjusted the data types to their proper forms. This summarizing function quantifies each variable in a manner consistent with their types. We notice the levels of each factor in the 'Stats/Values' column, the frequency of valid (non-missing) observations per level of our factors, and the quantity and percent missing alongside them. We review these statistics to identify any issues with each variable.\n\n\n::: {.cell hash='LendingApproval_cache/html/loan_data_summary_cab2f4f39c7080f1d0df4bc58620a9c1'}\n\n```{.r .cell-code}\ndfSummary(loan_data, style = 'grid', graph.col = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"No\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Variable\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Stats / Values\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Freqs (% of Valid)\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Valid\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Missing\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1\",\"2\":\"Gender\\\\\\\\\\\\n[factor]\",\"3\":\"1\\\\\\\\. Female\\\\\\\\\\\\n2\\\\\\\\. Male\",\"4\":\"\\\\\\\\112 (18.6%)\\\\\\\\\\\\n\\\\\\\\489 (81.4%)\",\"5\":\"601\\\\\\\\\\\\n(97.9%)\",\"6\":\"13\\\\\\\\\\\\n(2.1%)\",\"_rn_\":\"1\"},{\"1\":\"2\",\"2\":\"Married\\\\\\\\\\\\n[factor]\",\"3\":\"1\\\\\\\\. No\\\\\\\\\\\\n2\\\\\\\\. Yes\",\"4\":\"\\\\\\\\213 (34.9%)\\\\\\\\\\\\n\\\\\\\\398 (65.1%)\",\"5\":\"611\\\\\\\\\\\\n(99.5%)\",\"6\":\"3\\\\\\\\\\\\n(0.5%)\",\"_rn_\":\"2\"},{\"1\":\"3\",\"2\":\"Dependents\\\\\\\\\\\\n[factor]\",\"3\":\"1\\\\\\\\. 0\\\\\\\\\\\\n2\\\\\\\\. 1\\\\\\\\\\\\n3\\\\\\\\. 2\\\\\\\\\\\\n4\\\\\\\\. 3+\",\"4\":\"\\\\\\\\345 (57.6%)\\\\\\\\\\\\n\\\\\\\\102 (17.0%)\\\\\\\\\\\\n\\\\\\\\101 (16.9%)\\\\\\\\\\\\n\\\\\\\\ 51 ( 8.5%)\",\"5\":\"599\\\\\\\\\\\\n(97.6%)\",\"6\":\"15\\\\\\\\\\\\n(2.4%)\",\"_rn_\":\"3\"},{\"1\":\"4\",\"2\":\"Education\\\\\\\\\\\\n[factor]\",\"3\":\"1\\\\\\\\. Graduate\\\\\\\\\\\\n2\\\\\\\\. Not Graduate\",\"4\":\"\\\\\\\\480 (78.2%)\\\\\\\\\\\\n\\\\\\\\134 (21.8%)\",\"5\":\"614\\\\\\\\\\\\n(100.0%)\",\"6\":\"0\\\\\\\\\\\\n(0.0%)\",\"_rn_\":\"4\"},{\"1\":\"5\",\"2\":\"Self_Employed\\\\\\\\\\\\n[factor]\",\"3\":\"1\\\\\\\\. No\\\\\\\\\\\\n2\\\\\\\\. Yes\",\"4\":\"\\\\\\\\500 (85.9%)\\\\\\\\\\\\n\\\\\\\\ 82 (14.1%)\",\"5\":\"582\\\\\\\\\\\\n(94.8%)\",\"6\":\"32\\\\\\\\\\\\n(5.2%)\",\"_rn_\":\"5\"},{\"1\":\"6\",\"2\":\"ApplicantIncome\\\\\\\\\\\\n[integer]\",\"3\":\"Mean (sd) : 5403.5 (6109)\\\\\\\\\\\\nmin < med < max:\\\\\\\\\\\\n150 < 3812.5 < 81000\\\\\\\\\\\\nIQR (CV) : 2917.5 (1.1)\",\"4\":\"505 distinct values\",\"5\":\"614\\\\\\\\\\\\n(100.0%)\",\"6\":\"0\\\\\\\\\\\\n(0.0%)\",\"_rn_\":\"6\"},{\"1\":\"7\",\"2\":\"CoapplicantIncome\\\\\\\\\\\\n[numeric]\",\"3\":\"Mean (sd) : 1621.2 (2926.2)\\\\\\\\\\\\nmin < med < max:\\\\\\\\\\\\n0 < 1188.5 < 41667\\\\\\\\\\\\nIQR (CV) : 2297.2 (1.8)\",\"4\":\"287 distinct values\",\"5\":\"614\\\\\\\\\\\\n(100.0%)\",\"6\":\"0\\\\\\\\\\\\n(0.0%)\",\"_rn_\":\"7\"},{\"1\":\"8\",\"2\":\"LoanAmount\\\\\\\\\\\\n[integer]\",\"3\":\"Mean (sd) : 146.4 (85.6)\\\\\\\\\\\\nmin < med < max:\\\\\\\\\\\\n9 < 128 < 700\\\\\\\\\\\\nIQR (CV) : 68 (0.6)\",\"4\":\"203 distinct values\",\"5\":\"592\\\\\\\\\\\\n(96.4%)\",\"6\":\"22\\\\\\\\\\\\n(3.6%)\",\"_rn_\":\"8\"},{\"1\":\"9\",\"2\":\"Loan_Amount_Term\\\\\\\\\\\\n[integer]\",\"3\":\"Mean (sd) : 342 (65.1)\\\\\\\\\\\\nmin < med < max:\\\\\\\\\\\\n12 < 360 < 480\\\\\\\\\\\\nIQR (CV) : 0 (0.2)\",\"4\":\"12 :   1 ( 0.2%)\\\\\\\\\\\\n 36 :   2 ( 0.3%)\\\\\\\\\\\\n 60 :   2 ( 0.3%)\\\\\\\\\\\\n 84 :   4 ( 0.7%)\\\\\\\\\\\\n120 :   3 ( 0.5%)\\\\\\\\\\\\n180 :  44 ( 7.3%)\\\\\\\\\\\\n240 :   4 ( 0.7%)\\\\\\\\\\\\n300 :  13 ( 2.2%)\\\\\\\\\\\\n360 : 512 (85.3%)\\\\\\\\\\\\n480 :  15 ( 2.5%)\",\"5\":\"600\\\\\\\\\\\\n(97.7%)\",\"6\":\"14\\\\\\\\\\\\n(2.3%)\",\"_rn_\":\"9\"},{\"1\":\"10\",\"2\":\"Credit_History\\\\\\\\\\\\n[factor]\",\"3\":\"1\\\\\\\\. 0\\\\\\\\\\\\n2\\\\\\\\. 1\",\"4\":\"\\\\\\\\ 89 (15.8%)\\\\\\\\\\\\n\\\\\\\\475 (84.2%)\",\"5\":\"564\\\\\\\\\\\\n(91.9%)\",\"6\":\"50\\\\\\\\\\\\n(8.1%)\",\"_rn_\":\"10\"},{\"1\":\"11\",\"2\":\"Property_Area\\\\\\\\\\\\n[factor]\",\"3\":\"1\\\\\\\\. Rural\\\\\\\\\\\\n2\\\\\\\\. Semiurban\\\\\\\\\\\\n3\\\\\\\\. Urban\",\"4\":\"\\\\\\\\179 (29.2%)\\\\\\\\\\\\n\\\\\\\\233 (37.9%)\\\\\\\\\\\\n\\\\\\\\202 (32.9%)\",\"5\":\"614\\\\\\\\\\\\n(100.0%)\",\"6\":\"0\\\\\\\\\\\\n(0.0%)\",\"_rn_\":\"11\"},{\"1\":\"12\",\"2\":\"Loan_Status\\\\\\\\\\\\n[factor]\",\"3\":\"1\\\\\\\\. N\\\\\\\\\\\\n2\\\\\\\\. Y\",\"4\":\"\\\\\\\\192 (31.3%)\\\\\\\\\\\\n\\\\\\\\422 (68.7%)\",\"5\":\"614\\\\\\\\\\\\n(100.0%)\",\"6\":\"0\\\\\\\\\\\\n(0.0%)\",\"_rn_\":\"12\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThere are 7 columns that have missing values. The proportion of values for several columns shows significant differences and skew. For example, 97.9% of this dataset contains males applicants based on observations of the Gender variable, 99.5% of applicants are married people given the Married variable, and over 90% of our observations have longer Credit_History. Due to the disproportionate levels within the variables we should expect the data is not representative of a larger population unless that population happens to have similar proportions.\n\nOur numeric incomes variables show significant signs of skew through the differences in their mean and medians as well as their ranges. The lowest applicant income was 150, while the highest was 81000. A similar problem exists with our co-applicant income data having had individuals with 0 income on the lowest end of the range and 41667 on the highest.\n\nHowever, all of the observations contained an applicant and co-applicant income. Since some applicants may not have used a co-applicant on their applications, part of this skew could be caused by the data collection process. Additionally, we are only missing 3.6% of the observations of loan amount and 2.3% for loan terms.\n\nThere are regular intervals and commonality in the loan term amounts which indicates we may have been able to factorize their data types. We chose instead to leave it as a discrete numeric value since it represents the term length which could be any number of days or months. We note that 85.3% percent of these applicants applied for a loan term of 360 but we are unsure if that is due to the lending institutions standard practice or if applicants requested this specific term.\n\nFor exploratory purposes, we visualize the proportions to see just how skewed and disproportionate this dataset is. We include missing values to demonstrate their influence on the dataset as well. The chart below shows the distribution of all categorical variables, which includes the factors mentioned previously.\n\n\n::: {.cell fig.length='20' hash='LendingApproval_cache/html/cat-bar_0d69f0a3ecf8457b985e3aea66b1d1ac'}\n\n```{.r .cell-code}\n# select categorical columns\ncat_cols = c()\nj <- 1\nfor (i in 1:ncol(loan_data)) {\n  if (class((loan_data[,i])) == 'factor') {\n      cat_cols[j]=names(loan_data[i])\n      j <- j+1\n  }\n}\n\nloan_fact <-  loan_data[cat_cols]\n# long format\nloan_factm <- melt(loan_fact, measure.vars = cat_cols, variable.name = 'metric', value.name = 'value')\n\n# plot categorical columns\nggplot(loan_factm, aes(x = value)) + \n  geom_bar() + \n  scale_fill_brewer(palette = \"Set1\") + \n  facet_wrap( ~ metric, nrow = 5L, scales = 'free') + coord_flip()\n```\n\n::: {.cell-output-display}\n![](LendingApproval_files/figure-html/cat-bar-1.png){width=960}\n:::\n:::\n\n\nFrom this chart, it is very clear we have a dataset with mostly married male graduates with no dependents, a long credit history, and who are not self-employed. There is a relatively even mix of urban, suburban, and rural applicants and a small number of missing values. Applicants tend to be accepted more often than not and there are no missing observations for our target variable 'Loan_Status' nor the applicant's property area or education. These are all of our categorical variables.\n\nWe also generate histograms with the count of each observation to assess our numeric variable distributions. This will let us know more about the skewness, average values, and where potential outliers may be found for our numeric variables. The graph below shows their distributions.\n\n\n::: {.cell hash='LendingApproval_cache/html/plot_num_06f2b27f984e2cd3c114bff22db7f67d'}\n\n```{.r .cell-code}\nplot_histogram(loan_data, geom_histogram_args = list(\"fill\" = \"tomato4\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](LendingApproval_files/figure-html/plot_num-1.png){width=672}\n:::\n:::\n\n\nThe applicant income and co-applicant income variables are highly right skewed with a smaller number of individual applicants stretching the distribution towards higher incomes. For analysis purposes, we must keep in mind that only a handful of applicants had higher incomes while the bulk of applicants were concentrated at the lower end of the income distribution. The loan amount term has one spike at 360. Meanwhile, the loan amount is the closest to normal. These results are consistent with our summary table.\n\nTo review the impact of the categorical variables' proportions on loan approval in more detail, we isolate the factor levels individually. Here again, we visualize the proportions with and without missing values. Proportions are placed alongside each variable's frequency table. One example of this process, that of the amount of dependents for the individual, is shown.\n\n\n\n\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-2_760ca1d9ed863ca96de2bca198c9f061'}\n\n```{.r .cell-code}\ndf <- fact_freq_table %>% \n  dplyr::select(key, \"value\", \"freq\", percent) %>% \n  rename(name = value, value = freq)\ndf <- df %>% \n  filter(key == \"Dependents\") \n\nshiny::selectInput(inputId = \"type\", \n            label = strong(\"Factor Selection\"),\n            choices = unique(df$key),\n            selected = \"Dependents\")\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"form-group shiny-input-container\">\n<label class=\"control-label\" id=\"type-label\" for=\"type\">\n<strong>Factor Selection</strong>\n</label>\n<div>\n<select id=\"type\"><option value=\"Dependents\" selected>Dependents</option></select>\n<script type=\"application/json\" data-for=\"type\" data-nonempty=\"\">{\"plugins\":[\"selectize-plugin-a11y\"]}</script>\n</div>\n</div>\n```\n:::\n\n```{.r .cell-code}\nrobservable(\n  \"https://observablehq.com/@juba/draggable-pie-donut-chart\",\n  include = c(\"chart\", \"draw\"),\n  hide = \"draw\",\n  input = list(data = df),\n  width = 700\n)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-3c9bba3053bfb5a82798\" style=\"width:100%;height:445px;\" class=\"robservable html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-3c9bba3053bfb5a82798\">{\"x\":{\"notebook\":\"https://observablehq.com/@juba/draggable-pie-donut-chart\",\"include\":[\"chart\",\"draw\"],\"hide\":\"draw\",\"input\":{\"data\":[{\"key\":\"Dependents\",\"name\":\"0\",\"value\":345,\"percent\":56.19},{\"key\":\"Dependents\",\"name\":\"1\",\"value\":102,\"percent\":16.61},{\"key\":\"Dependents\",\"name\":\"2\",\"value\":101,\"percent\":16.45},{\"key\":\"Dependents\",\"name\":\"3+\",\"value\":51,\"percent\":8.31},{\"key\":\"Dependents\",\"name\":\"Missing\",\"value\":15,\"percent\":2.44}]},\"input_js\":[],\"observers\":null,\"update_height\":true,\"update_width\":true},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-3_a898a9ee096bd38fdefac117c148ab6e'}\n\n```{.r .cell-code}\nloan_dep <- with(loan_data, table(Dependents, Loan_Status)) %>% \n  prop.table(margin = 1) %>% as.data.frame() %>% filter(Loan_Status == 'Y')\nloan_dep\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Dependents\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"Loan_Status\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"Freq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\",\"2\":\"Y\",\"3\":\"0.6898551\"},{\"1\":\"1\",\"2\":\"Y\",\"3\":\"0.6470588\"},{\"1\":\"2\",\"2\":\"Y\",\"3\":\"0.7524752\"},{\"1\":\"3+\",\"2\":\"Y\",\"3\":\"0.6470588\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nAlthough we only show one example, the remaining examples confirm our thoughts about the dataset's disproportionalities. Missing values have little effect on the overall proportions and so they can simply be removed or omitted. It remains male dominated with applicants who are married, have no dependents, are highly educated, and have a long credit history.\n\n## Correlations\n\nTo determine how well each variable is correlated with our target variable and with one another, we construct a correlation plot. This plot contains the values of all correlation between variables represented by colors and numbers. The row we review the most is our target variable, 'Loan_Status.'\n\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-5_a9fd1528b983af0af9e4fa041f7642df'}\n\n```{.r .cell-code}\nG = cor(loan_data[6:(length(loan_data)-3)])\ncorrplot(G, method = 'number') # colorful number\n```\n\n::: {.cell-output-display}\n![](LendingApproval_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe numeric features do not seem to be strongly correlated with another so that is a factor that does not have to be dealt with.\n\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-6_203efded4a53068f679a090b47d85e79'}\n\n```{.r .cell-code}\nG = cor(loan_data[6:(length(loan_data)-3)])\ncorrplot(G, method = 'number') # colorful number\n```\n\n::: {.cell-output-display}\n![](LendingApproval_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nGiven that our numeric features have correlation values near 0, they do not seem to be strongly correlated with our target. They also do not seem to have any correlation with one another so this is a factor that does not have to be dealt with.\n\n# Data Preparation\n\n## Handling missing values\n\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-7_4a2b95bfa4ad64c20b6df13b89a30464'}\n\n```{.r .cell-code}\n# plot missing values\nplot_missing(loan_data)\n```\n\n::: {.cell-output-display}\n![](LendingApproval_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWe can see above credit_history contributes to 8% of missing data along with self_employed that accounts for more than 5% of missing data. All records having missing categorical predictors will be removed. Next we will impute numeric values using MICE (Multivariate Imputation by Chained Equations).\n\n\n::: {.cell hash='LendingApproval_cache/html/cat-missing_27a8a89f7e9b1712be4801ac96d29b4c'}\n\n```{.r .cell-code}\n# Filter out the data which has missing categorical predictors\nloan_data <- loan_data %>% filter(!is.na(Credit_History) &\n                                  !is.na(Self_Employed) &  \n                                  !is.na(Dependents) & \n                                  !is.na(Gender) & \n                                  !is.na(Married))\n```\n:::\n\n::: {.cell hash='LendingApproval_cache/html/num-missing_3ef76fbe6c0b7a96ec3243937cdd4c82'}\n\n```{.r .cell-code}\n# impute numeric predictors using mice\nloan_data <- complete(mice(data=loan_data, method=\"pmm\", print=FALSE))\n```\n:::\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-8_a7b411702f31fba1216632f9a43c71da'}\n\n```{.r .cell-code}\ndim(loan_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 511  12\n```\n:::\n:::\n\n\nFinally our clean dataset contains 511 rows and 12 columns.\n\n## Preprocess using transformation\n\nWe have seen above that numeric features are right skewed so in this step we will use caret `preprocess` method using box cox, center and scale transformation.\n\n\n::: {.cell hash='LendingApproval_cache/html/transform-train_31610bad4abae669f49e86971bbb5770'}\n\n```{.r .cell-code}\n# library(e1071) - where this was used\nset.seed(622)\nloan_data <- loan_data %>% \n  dplyr::select(c(\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\")) %>%\n  preProcess(method = c(\"BoxCox\",\"center\",\"scale\")) %>% \n  predict(loan_data)\n```\n:::\n\n\n## Training and Test Partition\n\nIn this step for data preparation we will partition the training dataset in training and validation sets using `createDataPartition` method from `caret` package. We will reserve 75% for training and rest 25% for validation purpose.\n\n\n::: {.cell hash='LendingApproval_cache/html/partition_b242e45dc82e4a7d2b9dd8e7d8596148'}\n\n```{.r .cell-code}\nset.seed(622)\npartition <- createDataPartition(loan_data$Loan_Status, p=0.75, list = FALSE)\n\ntraining <- loan_data[partition,]\ntesting <- loan_data[-partition,]\n\n# training/validation partition for independent variables\n#X.train <- ld.clean[partition, ] %>% dplyr::select(-Loan_Status)\n#X.test <- ld.clean[-partition, ] %>% dplyr::select(-Loan_Status)\n\n# training/validation partition for dependent variable Loan_Status\n#y.train <- ld.clean$Loan_Status[partition]\n#y.test <- ld.clean$Loan_Status[-partition]\n```\n:::\n\n\n# Build Models\n\n## Linear Discriminant Analysis (LDA)\n\n\n::: {.cell hash='LendingApproval_cache/html/lda_2b9bebed209ebba21ad95fe843727f61'}\n\n```{.r .cell-code}\n# LDA model\nlda_model <- lda(Loan_Status~., data = loan_data)\nlda_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nlda(Loan_Status ~ ., data = loan_data)\n\nPrior probabilities of groups:\n        N         Y \n0.3209393 0.6790607 \n\nGroup means:\n  GenderMale MarriedYes Dependents1 Dependents2 Dependents3+\nN  0.7926829  0.5792683   0.1829268   0.1341463   0.09756098\nY  0.8357349  0.6801153   0.1585014   0.1902017   0.08069164\n  EducationNot Graduate Self_EmployedYes ApplicantIncome CoapplicantIncome\nN             0.2682927        0.1463415     0.003576320         0.0571435\nY             0.1902017        0.1325648    -0.001690249        -0.0270073\n   LoanAmount Loan_Amount_Term Credit_History1 Property_AreaSemiurban\nN  0.07966414      0.016992352       0.5548780              0.2682927\nY -0.03765106     -0.008030968       0.9798271              0.4409222\n  Property_AreaUrban\nN          0.3719512\nY          0.2997118\n\nCoefficients of linear discriminants:\n                                LD1\nGenderMale              0.185159211\nMarriedYes              0.375755462\nDependents1            -0.209004726\nDependents2             0.137509542\nDependents3+            0.007142953\nEducationNot Graduate  -0.294391997\nSelf_EmployedYes       -0.025905262\nApplicantIncome        -0.012085555\nCoapplicantIncome      -0.106529320\nLoanAmount             -0.099136040\nLoan_Amount_Term       -0.049820158\nCredit_History1         3.073804026\nProperty_AreaSemiurban  0.616732100\nProperty_AreaUrban      0.066231320\n```\n:::\n:::\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-9_d7e2ea96b017deee1105e05c1561cf38'}\n\n```{.r .cell-code}\n# prediction from lda model\nlda_predict <- lda_model %>% \n  predict(testing)\n```\n:::\n\n::: {.cell hash='LendingApproval_cache/html/lda-accuracy_d4c409d1b25fc91bc364168c1c12d18f'}\n\n```{.r .cell-code}\n# accuracy\nmean(lda_predict$class==testing$Loan_Status)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8110236\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(lda_predict$class, testing$Loan_Status)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  N  Y\n         N 19  2\n         Y 22 84\n                                        \n               Accuracy : 0.811         \n                 95% CI : (0.732, 0.875)\n    No Information Rate : 0.6772        \n    P-Value [Acc > NIR] : 0.0005479     \n                                        \n                  Kappa : 0.5046        \n                                        \n Mcnemar's Test P-Value : 0.0001052     \n                                        \n            Sensitivity : 0.4634        \n            Specificity : 0.9767        \n         Pos Pred Value : 0.9048        \n         Neg Pred Value : 0.7925        \n             Prevalence : 0.3228        \n         Detection Rate : 0.1496        \n   Detection Prevalence : 0.1654        \n      Balanced Accuracy : 0.7201        \n                                        \n       'Positive' Class : N             \n                                        \n```\n:::\n:::\n\n\nLDA model accuracy comes out as \\~81%\n\n## K-nearest neighbor (KNN)\n\n\n::: {.cell hash='LendingApproval_cache/html/knn_4b987550e997a1e53c07e5233b4262e0'}\n\n```{.r .cell-code}\n# KNN model\nset.seed(622)\ntrain.knn <- training[, names(training) != \"Direction\"]\nprep <- preProcess(x = train.knn, method = c(\"center\", \"scale\"))\nprep\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCreated from 384 samples and 12 variables\n\nPre-processing:\n  - centered (4)\n  - ignored (8)\n  - scaled (4)\n```\n:::\n\n```{.r .cell-code}\ncl <- trainControl(method=\"repeatedcv\", repeats = 5) \nknn_model <- train(Loan_Status ~ ., data = training, \n                method = \"knn\", \n                trControl = cl, \n                preProcess = c(\"center\",\"scale\"), \n                tuneLength = 20)\nknn_model \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nk-Nearest Neighbors \n\n384 samples\n 11 predictor\n  2 classes: 'N', 'Y' \n\nPre-processing: centered (14), scaled (14) \nResampling: Cross-Validated (10 fold, repeated 5 times) \nSummary of sample sizes: 346, 346, 346, 345, 346, 345, ... \nResampling results across tuning parameters:\n\n  k   Accuracy   Kappa    \n   5  0.7590209  0.3575145\n   7  0.7689406  0.3751117\n   9  0.7725985  0.3746036\n  11  0.7782524  0.3884713\n  13  0.7829615  0.3994494\n  15  0.7787908  0.3849571\n  17  0.7689528  0.3503238\n  19  0.7642294  0.3309567\n  21  0.7647551  0.3299468\n  23  0.7548097  0.2947001\n  25  0.7454298  0.2607665\n  27  0.7412733  0.2448000\n  29  0.7402746  0.2423939\n  31  0.7365911  0.2319391\n  33  0.7292901  0.2050164\n  35  0.7251066  0.1885755\n  37  0.7178596  0.1615955\n  39  0.7126768  0.1383143\n  41  0.7100317  0.1282468\n  43  0.7084798  0.1212857\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 13.\n```\n:::\n:::\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-10_ac6e04716814366746f17aeb06499f98'}\n\n```{.r .cell-code}\n# prediction from knn model\nplot(knn_model)\n```\n\n::: {.cell-output-display}\n![](LendingApproval_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nknn_predict <- predict(knn_model,newdata = testing)\nmean(knn_predict == testing$Loan_Status) # accuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7952756\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(knn_predict, testing$Loan_Status)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  N  Y\n         N 17  2\n         Y 24 84\n                                          \n               Accuracy : 0.7953          \n                 95% CI : (0.7146, 0.8617)\n    No Information Rate : 0.6772          \n    P-Value [Acc > NIR] : 0.002202        \n                                          \n                  Kappa : 0.4553          \n                                          \n Mcnemar's Test P-Value : 3.814e-05       \n                                          \n            Sensitivity : 0.4146          \n            Specificity : 0.9767          \n         Pos Pred Value : 0.8947          \n         Neg Pred Value : 0.7778          \n             Prevalence : 0.3228          \n         Detection Rate : 0.1339          \n   Detection Prevalence : 0.1496          \n      Balanced Accuracy : 0.6957          \n                                          \n       'Positive' Class : N               \n                                          \n```\n:::\n:::\n\n\nKNN model accuracy comes out as \\~80%\n\n## Decision Trees\n\n\n::: {.cell hash='LendingApproval_cache/html/Decision_a181bbef43c89a2a66a3c91261545067'}\n\n```{.r .cell-code}\n# Decision Trees model\nset.seed(622)\ntree.loans = tree(Loan_Status~., data=training)\nsummary(tree.loans)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nClassification tree:\ntree(formula = Loan_Status ~ ., data = training)\nVariables actually used in tree construction:\n[1] \"Credit_History\"    \"Property_Area\"     \"CoapplicantIncome\"\nNumber of terminal nodes:  5 \nResidual mean deviance:  0.921 = 349 / 379 \nMisclassification error rate: 0.1849 = 71 / 384 \n```\n:::\n\n```{.r .cell-code}\nplot(tree.loans)\ntext(tree.loans, pretty = 0)\n```\n\n::: {.cell-output-display}\n![](LendingApproval_files/figure-html/Decision-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-11_a4181eada9d0411f9f3a1ad4ac759a7a'}\n\n```{.r .cell-code}\n# prediction from decision tree model\ntree.predict<-predict(tree.loans, testing, type = 'class')\nmean(tree.predict == testing$Loan_Status) # accuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7952756\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(tree.predict, testing$Loan_Status)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  N  Y\n         N 19  4\n         Y 22 82\n                                          \n               Accuracy : 0.7953          \n                 95% CI : (0.7146, 0.8617)\n    No Information Rate : 0.6772          \n    P-Value [Acc > NIR] : 0.0022025       \n                                          \n                  Kappa : 0.471           \n                                          \n Mcnemar's Test P-Value : 0.0008561       \n                                          \n            Sensitivity : 0.4634          \n            Specificity : 0.9535          \n         Pos Pred Value : 0.8261          \n         Neg Pred Value : 0.7885          \n             Prevalence : 0.3228          \n         Detection Rate : 0.1496          \n   Detection Prevalence : 0.1811          \n      Balanced Accuracy : 0.7085          \n                                          \n       'Positive' Class : N               \n                                          \n```\n:::\n:::\n\n\nDecision Tree model accuracy comes out as \\~80%\n\n## Random Forests\n\n\n::: {.cell hash='LendingApproval_cache/html/rf_56c35b92442e288f792eda4fe342704f'}\n\n```{.r .cell-code}\nset.seed(622)\n# Random Forest model\nrf.loans <- randomForest(Loan_Status~., data = training)\nrf.loans\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\n randomForest(formula = Loan_Status ~ ., data = training) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n        OOB estimate of  error rate: 20.57%\nConfusion matrix:\n   N   Y class.error\nN 59  64  0.52032520\nY 15 246  0.05747126\n```\n:::\n:::\n\n::: {.cell hash='LendingApproval_cache/html/unnamed-chunk-12_8365b178b26cfe229f7c7fccd3a32e31'}\n\n```{.r .cell-code}\n# prediction from random forest model\nrf.predict <- predict(rf.loans, testing,type='class')\nmean(rf.predict == testing$Loan_Status) # accuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8110236\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(rf.predict, testing$Loan_Status)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  N  Y\n         N 22  5\n         Y 19 81\n                                        \n               Accuracy : 0.811         \n                 95% CI : (0.732, 0.875)\n    No Information Rate : 0.6772        \n    P-Value [Acc > NIR] : 0.0005479     \n                                        \n                  Kappa : 0.5254        \n                                        \n Mcnemar's Test P-Value : 0.0079635     \n                                        \n            Sensitivity : 0.5366        \n            Specificity : 0.9419        \n         Pos Pred Value : 0.8148        \n         Neg Pred Value : 0.8100        \n             Prevalence : 0.3228        \n         Detection Rate : 0.1732        \n   Detection Prevalence : 0.2126        \n      Balanced Accuracy : 0.7392        \n                                        \n       'Positive' Class : N             \n                                        \n```\n:::\n:::\n\n\nRandom Forest model accuracy comes out as \\~80%\n\n# Model Performance\n\nAll 4 of the models we built above have an accuracy rate of around 80% with the Random Forest and LDA model getting the light edge in accuracy (81.1% to 79.5%)\n\nWe will look at some more detailed accuracy metrics produced from the predict function.\n\n\n::: {.cell hash='LendingApproval_cache/html/model-performance_a26406f0e03c1085b1ce4be91262a4f5'}\n\n```{.r .cell-code  code-summary=\"Model Performance\"}\nmodel_performance_table <- data.frame(matrix(c(\n         \"Linear Discriminant Analysis (LDA)\", \n         0.732, 0.875, (0.875-0.732), \n         0.811, 0.720, 0.463, 0.977,\n         0.505, 0.905, 0.001,\n         \"K-Nearest Neighbor (KNN)\", \n         0.715, 0.862, (0.862-0.715),\n         0.795, 0.696, 0.415, 0.977,\n         0.455, 0.895, 0.002,\n         \"Decision Trees (DTs)\", \n         0.715, 0.862, (0.862-0.715),\n         0.795, 0.709, 0.463, 0.954,\n         0.471, 0.826, 0.001, \n         \"Random Forests (RFs)\", \n         0.732, 0.875, (0.875-0.732),\n         0.811, 0.739, 0.537, 0.942,\n         0.525, 0.815, 0.001),\n         nrow = 4, byrow = T))\ncolnames(model_performance_table) <- c(\"ID\", \n                               \"Lower\", \n                               \"Upper\", \n                               \"Range & Variation\",\n                               \"Accuracy\",\n                              \"Sensitivity\", \n                              \"Specificity\",\n                              \"Balanced Accuracy\",\n                              \"Kappa\", \n                              \"True Positives\", \n                              \"P-value\")\nmodel_performance_table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"ID\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Lower\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Upper\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Range & Variation\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Accuracy\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Sensitivity\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Specificity\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Balanced Accuracy\"],\"name\":[8],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Kappa\"],\"name\":[9],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"True Positives\"],\"name\":[10],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"P-value\"],\"name\":[11],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Linear Discriminant Analysis (LDA)\",\"2\":\"0.732\",\"3\":\"0.875\",\"4\":\"0.143\",\"5\":\"0.811\",\"6\":\"0.72\",\"7\":\"0.463\",\"8\":\"0.977\",\"9\":\"0.505\",\"10\":\"0.905\",\"11\":\"0.001\"},{\"1\":\"K-Nearest Neighbor (KNN)\",\"2\":\"0.715\",\"3\":\"0.862\",\"4\":\"0.147\",\"5\":\"0.795\",\"6\":\"0.696\",\"7\":\"0.415\",\"8\":\"0.977\",\"9\":\"0.455\",\"10\":\"0.895\",\"11\":\"0.002\"},{\"1\":\"Decision Trees (DTs)\",\"2\":\"0.715\",\"3\":\"0.862\",\"4\":\"0.147\",\"5\":\"0.795\",\"6\":\"0.709\",\"7\":\"0.463\",\"8\":\"0.954\",\"9\":\"0.471\",\"10\":\"0.826\",\"11\":\"0.001\"},{\"1\":\"Random Forests (RFs)\",\"2\":\"0.732\",\"3\":\"0.875\",\"4\":\"0.143\",\"5\":\"0.811\",\"6\":\"0.739\",\"7\":\"0.537\",\"8\":\"0.942\",\"9\":\"0.525\",\"10\":\"0.815\",\"11\":\"0.001\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIn this particular case, since the accuracy results are so similar it is wise to examine which models are most often leading to type 1 or type 2 errors. Assuming a null hypothesis is not giving a loan, a type 1 error is giving someone a loan when they should not have gotten one and a type 2 error is not giving someone a loan when they should have gotten one. This correlates to the sensitivity and specificity respectively.\n\nThe balanced accuracy metric takes the mean of sensitivity and specificity in order to diagnose if a model appears to be accurate but is really only predicting the positive or negative case correctly. In this case the random forest model has a slight edge over the LDA in balanced accuracy (0.739 to 0.7201). This metric should be considered most impactful in our decision-making process since it directly contributes to the type of risk that will have to be managed in a portfolio.\n\nAlthough the LDA has the smallest p-value it is still \\<0.0025 for all models. They can all be used so this does not help us decide which model to choose. The same can be said for the Mcnemar's p-value.\n\nThe random forest also has the best Kappa score of 0.525. The Kappa score can be a much more accurate indicator of accuracy then the standard accuracy rate. The kappa score takes into account the expected accuracy of a model given the instances of each class. This helps a lot with unbalanced class numbers in the dataset. It is encouraging to see that our random forest model's Kappa is also the highest because this corresponds with it having the highest expected accuracy of our models in production.\n\nGiven that our random forest and LDA models have nearly equal accuracy, the same low-amount of variations present in their predictions, and reasonable kappa scores, either could be used with similar results. However, it is also important to consider context. The priority for business is to ensure loans are paid and lower the risk of loss or credit damage. For this reason, it may be beneficial to focus on the type 1 error rate, if we do not care how many people do not get loans when they should have. Otherwise, the more holistic metric of balanced accuracy ensures that more people get approved for loans when needed. \n\nIt is also important to consider our data assets. The LDA model requires fewer inputs to produce an output with nearly identical accuracy as the random forest model. If we were in a highly competitive market for data assets then a reduction in input for equally accurate predictive results could be more important than any performance score. Therefore, in resource competitive environments, the LDA would be the preferred model method since it can produce the highest balanced accuracy. \n\n\n# Conclusion\n\nAfter reviewing the results of 4 different models (LDA, KNN, Decision Tree, and Random Forest), we found that LDA is the most accurate by balanced accuracy and should be considered the best model in competitive resource limited environments. However, the performance metrics for these 4 models were very close. Depending on the stakeholders, it may be wise to recommend the random forest model with the caveat that greater resources would need to be devoted to it to produce slightly higher sensitivity scores. \n\nWhen attempting to minimize risk as much as possible and avoid purchasing data assets, the LDA model provides the best insights. If the lender is willing to provide more loans at a greater level of risk, then, based on this data set, the random forest would be better suited for this task.\n\nTo improve upon these metrics and gain better predictive power we should consider feature engineering and exploring new model types. Some models may be able to produce the same results with fewer features and if data collection resources are of concern, such a model would be essential to avoid paying for new features or data sets. There may also be undiscovered relationships between variables that can be used to better estimate likelihood of repayment and provide new insights.\n\nTo see the full report and source code, [visit my Github site](https://github.com/palmorezm/showcase/tree/master/posts/Loan%20Assessment).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/htmlwidgets-1.5.4/htmlwidgets.js\"></script>\r\n<script src=\"../../site_libs/robservable-binding-0.2.2/robservable.js\"></script>\r\n<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}