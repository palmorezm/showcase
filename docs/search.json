[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Zach Palmore is currently working as a Data Scientist in Rock County, WI. When not innovating data pipelines, he enjoys spending time gardening and making homemade pizzas.\nM.S. Data Science"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Risk Modeling and Prediction",
    "section": "",
    "text": "A Credit Risk Assessment for Lenders\n\n\n\n\npredictive\n\n\nmodeling\n\n\ndata science\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2022\n\n\nZach Palmore\n\n\n\n\n\n\n  \n\n\n\n\n\nPredicting Value of Unknown Variables\n\n\n\n\npredictive\n\n\nmodeling\n\n\ndata science\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2022\n\n\nZach Palmore\n\n\n\n\n\n\n  \n\n\n\n\n\nAn Auto Insurance Example\n\n\n\n\npredictive\n\n\nmodeling\n\n\ndata science\n\n\n\n\n\n\n\n\n\n\n\nAug 14, 2022\n\n\nZach Palmore\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Insurance Claim Prediction/index.html#the-challenge",
    "href": "posts/Insurance Claim Prediction/index.html#the-challenge",
    "title": "Claim Estimation",
    "section": "The Challenge",
    "text": "The Challenge\nA key part of insurance is charging each customer the appropriate price for the risk they represent.\nThe challenge is knowing what is most likely to happen before it occurs. If we have confidence in what could occur, then we may better manage our risk. Data science offers a solution to this challenge. Developing advanced computational models with the capacity to crunch high volume data allows us to calculate probabilities of risk for many individuals at scale.\nThe business need is to predict the probability that a person will submit a claim and then estimate that claim amount. Multiple linear regression and binary logistic regression models were built to answer these questions. We explore, analyze and model with a data set containing records of customer behavior at an auto insurance company. A table with a selection of five variables that represent behavioral characteristics from customer records is shown below with a brief description of each for reference.\n\n\nCode\n# short descriptions of variables as table from matrix\nvardesc <- data.frame(matrix(c(\n'TARGET_FLAG',  'Was a claim submitted? 1 = Yes, 0 = No',\n'TARGET_AMT',   'Estimated amount of claim',\n'CLM_FREQ', 'Number of claims filed in past five years',\n'MVR_PTS',  'Motor vehicle inspection points',\n'TRAVETIME',    'Distance to work in minutes'\n),  byrow = TRUE, ncol = 2))\ncolnames(vardesc) <- c('Variable', 'Description')\nkbl(vardesc, booktabs = T, caption = \"Variable Descriptions\") %>%\n  kable_styling(latex_options = c(\"striped\", \"HOLD_position\"), full_width = F)\n\n\n\n\nVariable Descriptions\n \n  \n    Variable \n    Description \n  \n \n\n  \n    TARGET_FLAG \n    Was a claim submitted? 1 = Yes, 0 = No \n  \n  \n    TARGET_AMT \n    Estimated amount of claim \n  \n  \n    CLM_FREQ \n    Number of claims filed in past five years \n  \n  \n    MVR_PTS \n    Motor vehicle inspection points \n  \n  \n    TRAVETIME \n    Distance to work in minutes"
  },
  {
    "objectID": "posts/Insurance Claim Prediction/index.html#data-prep",
    "href": "posts/Insurance Claim Prediction/index.html#data-prep",
    "title": "Claim Estimation",
    "section": "Data Prep",
    "text": "Data Prep\nThere are over 8000 records in this data set, with 26 variables in each record. We begin by loading in the data and exploring.\nWhen exploring we look for missing values and abnormalities and try to find patterns in the records. We calculate some descriptive and inferential statistics that show the characteristics present in the data. These statistics inform us if imputations, transformations, or other adjustments are needed. For example, this violin plot with a box plot inlay, provides a wealth of information.\n\n\nKernel Density Estimation & Outliers\ntdata %>% \n  select_if(is.numeric) %>% \n  gather() %>% \n  ggplot(aes(value, key)) +\n  facet_wrap(~ key, scales = \"free\") +\n  geom_violin(aes(color = key, alpha = 1)) + \n  geom_boxplot(aes(fill = key, alpha = .5), notch = TRUE, size = .1, lty = 3) +  \n  stat_summary(fun.y = mean, geom = \"point\",\n               shape = 8, size = 1.5, color = \"#000000\") + \n  theme_minimal() + \n  theme(axis.text = element_blank(), \n        axis.title = element_blank(), \n        legend.position = \"none\", plot.title = element_text(hjust = 0.5)) + \n  labs(title = \"Kernel Density Estimation & Outliers\") \n\n\n\n\n\nPerhaps one of the easiest things to spot in this plot are outliers, shown as grey dots on the left and right sides of the variables. These points are located far from where the rest of the data is, and there are so many that some dots appear solid black due to repeated grey dots plotted in the same spot. Our target amount, the value we intend to predict, is a great example of a distribution with a lot of outliers. These points give a good idea of what ‘normal’ is for each variable but this plot offers some more.\nIn this plot the asterisk near the center of each boxplot is the median of the distribution for all records that contain the variable named, however, what exactly the median is less important than where it lies within the distribution. The top and bottom edges (the curvy colored lines) of the violin plot use the non-parametric method kernel density estimation (KDE) to smoothly estimate the probability of a value occurring anywhere along its range. Here again, we already notice problems with our target amount. Although not every variable follows this pattern. For these reasons, we need to be careful about how we handle this data before making any predictions.\nAnother method used to explore and prepare the data is a correlation plot. These examine the strength of relationships between variables, whether they are positive or negative, and how they compare to one another. We take a look at some selected variables in hopes that they confirm some expectations.\n\n\nCorrelation Plot\ntdata %>%\n  select_if(is.numeric) %>% \n  cor() %>% \n  ggcorrplot(method = \"circle\", type=\"upper\", \n             ggtheme = ggplot2::theme_minimal, legend.title = \"Influence\") + coord_flip() \n\n\n\n\n\nIf we are trying to predict the amount of a claim and we have a true or false variable indicating the presence or absences of claim submission (TARGET_FLAG) and the claim amount (TARGET_AMT), shouldn’t we expect the two to be correlated? I would hope so, given that, when an individual does not file a claim, the resultant claim amount is 0. We notice this in the big red circle towards the bottom left of the screen. This shows a strong positive correlation between the amount of a claim and presence of a claim. From this correlation plot we start to confirm these expectations and validate some conventional auto insurance knowledge.\nThese demonstrate only two ways to look at data before model building. However, to ensure that a model functions in the real world, a multitude of exploratory methods should be used to fully understand the data. To keep it brief, the data is split 70-30 into training and testing data sets, then cleaned up with using the multiple imputation by chained equations (MICE) method, perform a Yeo-Johnson transformation, and adjust other points as necessary to make the non-normal predictor appear normal enough for prediction. A quick look at the imputed summary statistics is shown for four numeric variables as a reference.\n\n\nImputed Summary Statistics\nimputed.stats.table <- data.frame(matrix(c(0,29707,54028,61469,83304,367030, \n         0,0,161160,155225,233352,885282,\n         1500,9280,14440,15710,20850,69740,\n         0,0,0,4037,4636,57037), ncol = 4, byrow = F)) \nnames(imputed.stats.table) <- c(\"Income\", \"Home Value\", \n                                \"Bluebook Value\", \"Old Claims\")\nimputed.stats.table <- imputed.stats.table %>% \n  mutate(Statistic = c(\"Min\", \"1st Quartile\", \"Median\", \n                       \"Mean\", \"3rd Qartile\", \"Max\")) %>%\n  dplyr::select(\"Statistic\", \"Income\", \"Home Value\", \n                \"Bluebook Value\", \"Old Claims\")\nkbl(imputed.stats.table,\n    booktabs = T,\n    caption = \"Imputed Summary Statistics\") %>%\n  kable_styling(latex_options = c(\"striped\", \"hold_position\"),\n                full_width = F)\n\n\n\n\nImputed Summary Statistics\n \n  \n    Statistic \n    Income \n    Home Value \n    Bluebook Value \n    Old Claims \n  \n \n\n  \n    Min \n    0 \n    0 \n    1500 \n    0 \n  \n  \n    1st Quartile \n    29707 \n    0 \n    9280 \n    0 \n  \n  \n    Median \n    54028 \n    161160 \n    14440 \n    0 \n  \n  \n    Mean \n    61469 \n    155225 \n    15710 \n    4037 \n  \n  \n    3rd Qartile \n    83304 \n    233352 \n    20850 \n    4636 \n  \n  \n    Max \n    367030 \n    885282 \n    69740 \n    57037"
  },
  {
    "objectID": "posts/Insurance Claim Prediction/index.html#model-building",
    "href": "posts/Insurance Claim Prediction/index.html#model-building",
    "title": "Claim Estimation",
    "section": "Model Building",
    "text": "Model Building\nOur objective was to build multiple linear regression and binomial logistic regression models to predict the amount of auto insurance claim. We explored, analyzed, and prepared the data as best we could in an attempt to improve the predictive outcome. The manner in which these were built is detailed in the Caret Model code chunk.\n\n\nCaret Models\n# Model 1: Establish Baseline\n# This models uses only previous accident as a predictor\nmodel1 <- glm(TARGET_FLAG ~ previous_accident, \n              family = binomial(link = \"logit\"), train)\n# Model 2: Experimentally Determine Best Features by Hand\n# These features were selected by alpha level and intuition\nmodel2 <- glm(TARGET_FLAG ~ previous_accident + \n                city + young + clean_rec + \n                educated, family = binomial(link = \"logit\"), train)\n# Model 3: Add Recommended Risk Predictors from III\n# This model takes another step towards improving accuracy \nmodel3 <- glm(TARGET_FLAG ~ previous_accident + \n                city + mstatus + income.values + \n                sex + car_use + educated + KIDSDRIV + \n                revoked, family = binomial(link = \"logit\"), \n              train)\n# Model 4: All in One\n# Examine results with all variables included, what worked?\nmodel4 <- lm(target_amt ~ ., train) \n# Model 5: Linear Regression with Dollar Estimators\n# This model leans heavy on the variables with specific dollar figures\nmodel5 <- lm(target_amt ~ income.values +\n               home.values + bluebook.values + \n               oldclaim.values + avg_claim, \n             train) \n# Model 6: Multidirectional StepAIC Regression\n# This uses a Stepwise Akaike Information Criteria to evaluate \n# and select predictors in the model with some special data prep\nmodel6 <- lm(target_amt ~ . -TARGET_AMT -TARGET_FLAG, train) \npm <- stepAIC(model6, trace = F, direction = \"both\")\n\n\nAnother model wherein everything but the kitchen sink was thrown at it (aptly known as the kitchen sink model), gave us insights into which variables were significant to use and what their effect on the model would probably be. Of course, with a model that contains over 30 variables, there is room for some complex interactions to occur. We rely on our exploration and analysis to guide us in the creation of additional models alongside the results from the kitchen sink model, historical model, and conventional wisdom from the auto insurance domain.\nSince we humans tend to poorly judge relationships represented as mathematical operations, a stepwise AIC model was created to do a lot of work for us. This model performs a check by cycling through the variables both forwards and backwards to pick the variables that are most likely to improve the predictive capacity of the model. The AIC just stands for Akaike Information Criterion which is an estimator of prediction error. In this model, when stepping (or cycling) through variables, we are using this criterion to select variables that reduce the amount of error present in the model. Ideally, this will improve model quality and output.\nWe finish with some general predictions of each model type. We created a historical model, kitchen sink model, a multidirectional stepwiseAIC, backward stepwiseAIC, high risk predictor model, and a conventional wisdom model using information from the Insurance Information Institute (III). These will be put to the test in the model selection process. Which one do you think will perform best?"
  },
  {
    "objectID": "posts/Insurance Claim Prediction/index.html#model-selection",
    "href": "posts/Insurance Claim Prediction/index.html#model-selection",
    "title": "Claim Estimation",
    "section": "Model Selection",
    "text": "Model Selection\nTo standardize the process of model selection, a function is created wherein all statistics are computed the same way. It begins by bringing in the holdout data we created in the data prep section. This is named the test data. With this we evaluate how accurately the model predicted the result. We then compute a confusion matrix which contains the rates of false positives, true positives, false negatives, and true negatives and estimate model specificity, sensitivity, precision, and recall with those values. These combined measures let us find the F1 score, and from them we can create a receiver operating characteristic (ROC) plot and find the area under the curve (AUC). These provide details about the accuracy and real-world effectiveness of a model.\nAs a quick reference, we show the results from one of the best models, that of the multidirectional stepwiseAIC. The receiver operating characteristic curve is plotted alongside text containing the accuracy, its bounds, how precise and sensitive it is as well as multiple significance values including McNemars p-value and an accuracy p-value. Each model went through this evaluation process.\n\n\nModel Summary\n# Create Function to Evaluate All Models\nmodstat <- function(model, test, \n                    target = \"TARGET_FLAG\", threshold = 0.5){\n  \n  # test model using predictions with test data\n  test$new <- ifelse(predict.glm(\n    model, test, \"response\") >= threshold, 1, 0) \n    \n    # create confusion matrix with stats\n    # shows true positive, false positive, and their inverse\n    cm <- confusionMatrix(factor(test$new), \n                          factor(test[[target]]), \"1\")\n    \n    # Organize information into data frame\n    df <- data.frame(obs = test$TARGET_FLAG, \n                     predicted = test$new, \n                     probs = predict(model, test))\n  \n  # Calculate performance and significance values\n  Pscores <- prediction(df$probs, \n                        df$obs)\n  \n  # AUC = \"Area Under the Curve\" \n  AUC <- performance(Pscores, \n                     measure = \"auc\")@y.values[[1]]\n    pscores <- performance(Pscores, \n                           \"tpr\", \"fpr\")\n  \n  # Plot the scores of true positive/ false positive\n    # This is a receiver operating characteristic (ROC) curve \n  plot(pscores,main=\"ROC Curve\", \n       sub = paste0(\"AUC: \", \n                    round(AUC, 3)))\n  \n  # Extract the F1 score \n    # place it below the plot for each model when run\n  results <- paste(cat(\"F1 = \", \n                       cm$byClass[7], \" \"), cm)\n  \n  # Output results with a ROC curve and all scores \n  return(results)\n}\n\n# Calculate and show ONLY model 6 for quick reference\nmodstat(model6, test)\n\n\n\n\n\nF1 =  0.4838057  \n\n\n[1] \" 1\"                                                                                                                                                                                                                                                                                                                                                                                             \n[2] \" c(1699, 113, 397, 239)\"                                                                                                                                                                                                                                                                                                                                                                        \n[3] \" c(Accuracy = 0.791666666666667, Kappa = 0.36653677545056, AccuracyLower = 0.775030346732191, AccuracyUpper = 0.807602177444679, AccuracyNull = 0.740196078431373, AccuracyPValue = 1.62575683811825e-09, McnemarPValue = 5.02353275353728e-36)\"                                                                                                                                                \n[4] \" c(Sensitivity = 0.375786163522013, Specificity = 0.937637969094923, `Pos Pred Value` = 0.678977272727273, `Neg Pred Value` = 0.810591603053435, Precision = 0.678977272727273, Recall = 0.375786163522013, F1 = 0.483805668016194, Prevalence = 0.259803921568627, `Detection Rate` = 0.0976307189542484, `Detection Prevalence` = 0.143790849673203, `Balanced Accuracy` = 0.656712066308468)\"\n[5] \" sens_spec\"                                                                                                                                                                                                                                                                                                                                                                                     \n[6] \" list()\""
  },
  {
    "objectID": "posts/Insurance Claim Prediction/index.html#conclusion",
    "href": "posts/Insurance Claim Prediction/index.html#conclusion",
    "title": "Claim Estimation",
    "section": "Conclusion",
    "text": "Conclusion\nRisk varies widely from customer to customer, and a deep understanding of different risk factors helps predict the likelihood and cost of insurance claims. Many factors contribute to the frequency and severity of car accidents including how, where and under what conditions people drive, as well as what they are driving. We developed 6 models. Half of these were multiple linear regression models and the other half were binomial logistic regression. Both have their benefits in the right context.\n\n\nComparison Table\nmod.stats.table <- data.frame(matrix(c(\n         \"Model 1\", 0.722, 0.757, 0.5, .01, \n         \"Model 2\", 0.732, 0.767, 0.58, 0.333,\n         \"Model 3\", 0.754, 0.788, 0.625, 0.422,\n         \"Model 4\", 0.998, 0.999, 0.999, 0.999, \n         \"Model 5\", 0.719, 0.753, 0.514, .090,\n         \"Model 6\", 0.775, 0.808, 0.657, 0.484),\n         nrow = 6, byrow = T))\ncolnames(mod.stats.table) <- c(\"ID\", \"Lower Bound\", \"Upper Bound\", \n                               \"Balanced Accuracy\", \"F1 Score\")\nmod.stats.table\n\n\n\n\n  \n\n\n\nWith an accuracy between 78 - 81%, the multidirectional stepwiseAIC model wins the contest between these two model types. It was also the most useful real-world model with a balanced accuracy at 65.7%. Its F1 score was 0.484, indicating the relationship between precision (how well it predicts true positives) and recall (ratio of correct positives in the predictions) is better than any other method of modeling.\nIn this table we reviewed the model’s lower and upper accuracy bounds, its balanced accuracy, and F1 scores. The results show Model 3, our other stepwiseAIC, is the runner up. Model 4 is the only model that appears to have been too effective, and is not realistic for a variety of reasons. Perhaps the most important being over-fitting.\nOf these factors in prediction, balanced accuracy is likely the best criteria to judge the models on in this scenario. This is because it finds arithmetic mean of sensitivity and specificity which tends to represent imbalanced data better than accuracy alone. Since our data set was highly imbalanced and the target class of claim amount appeared much less than the non-target class, this accuracy estimate helps balance expectations.\nOf course, these predictions could be improved. When building models, it may be a good idea to perform some feature engineering to better isolate the riskiest and least risky customers. Other model types may also offer new insights.\nFor more, view the full report on my GitHub page."
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html",
    "href": "posts/Loan Assessment/LendingApproval.html",
    "title": "Loan Approval",
    "section": "",
    "text": "The main source of income of lenders stems from their credit line. Can it be improved?"
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#data-characteristics",
    "href": "posts/Loan Assessment/LendingApproval.html#data-characteristics",
    "title": "Loan Approval",
    "section": "Data Characteristics",
    "text": "Data Characteristics\nThere are 614 observations of 12 variables. Each observation is an applicant’s application for a loan with its corresponding variables of interest. Below is the description of the variables of interest in the data set.\n\n\n\nVARIABLE NAME\nDESCRIPTION\n\n\n\n\nLoan_ID\nUnique Loan ID\n\n\nGender\nMale/ Female\n\n\nMarried\nApplicant married (Y/N)\n\n\nDependents\nNumber of dependents\n\n\nEducation\nApplicant Education (Graduate/ Undergraduate)\n\n\nSelf_Employed\nSelf employed (Y/N)\n\n\nApplicantIncome\nApplicant income\n\n\nCoapplicantIncome\nCoapplicant income\n\n\nLoanAmount\nLoan amount in thousands\n\n\nLoan_Amount_Term\nTerm of loan in months\n\n\nCredit_History\ncredit history meets guidelines\n\n\nProperty_Area\nUrban/ Semi Urban/ Rural\n\n\nLoan_Status\nLoan approved (Y/N)\n\n\n\nThere are four numeric variables represented by loan amount, loan amount term, applicant and co-applicant income. Several of these variables appear to be factors with specific levels but are not coded as such. For example, Gender, Married, Dependents, Education, Self_Employed, Property_Area, Credit_History, and Loan_Status are character strings. We will need to fix this if we are to make use of them.\n\n\nCode\n# read data, change blank to NA and and remove loan_id\nloan_data <- read.csv('https://raw.githubusercontent.com/amit-kapoor/Data622Group2/main/Loan_approval.csv') %>% \n  na_if(\"\") %>%\n  dplyr::select(-1)\n\n# categorical columns as factors\nloan_data <- loan_data %>% \n  mutate(Gender=as.factor(Gender),\n         Married=as.factor(Married),\n         Dependents=as.factor(Dependents),\n         Education=as.factor(Education),\n         Self_Employed=as.factor(Self_Employed),\n         Property_Area=as.factor(Property_Area),\n         Credit_History=as.factor(Credit_History),\n         Loan_Status=as.factor(Loan_Status))"
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#data-summary",
    "href": "posts/Loan Assessment/LendingApproval.html#data-summary",
    "title": "Loan Approval",
    "section": "Data summary",
    "text": "Data summary\nBelow is a summary of the loan approval dataset. For this process we have already adjusted the data types to their proper forms. This summarizing function quantifies each variable in a manner consistent with their types. We notice the levels of each factor in the ‘Stats/Values’ column, the frequency of valid (non-missing) observations per level of our factors, and the quantity and percent missing alongside them. We review these statistics to identify any issues with each variable.\n\n\nCode\ndfSummary(loan_data, style = 'grid', graph.col = FALSE)\n\n\n\n\n  \n\n\n\nThere are 7 columns that have missing values. The proportion of values for several columns shows significant differences and skew. For example, 97.9% of this dataset contains males applicants based on observations of the Gender variable, 99.5% of applicants are married people given the Married variable, and over 90% of our observations have longer Credit_History. Due to the disproportionate levels within the variables we should expect the data is not representative of a larger population unless that population happens to have similar proportions.\nOur numeric incomes variables show significant signs of skew through the differences in their mean and medians as well as their ranges. The lowest applicant income was 150, while the highest was 81000. A similar problem exists with our co-applicant income data having had individuals with 0 income on the lowest end of the range and 41667 on the highest.\nHowever, all of the observations contained an applicant and co-applicant income. Since some applicants may not have used a co-applicant on their applications, part of this skew could be caused by the data collection process. Additionally, we are only missing 3.6% of the observations of loan amount and 2.3% for loan terms.\nThere are regular intervals and commonality in the loan term amounts which indicates we may have been able to factorize their data types. We chose instead to leave it as a discrete numeric value since it represents the term length which could be any number of days or months. We note that 85.3% percent of these applicants applied for a loan term of 360 but we are unsure if that is due to the lending institutions standard practice or if applicants requested this specific term.\nFor exploratory purposes, we visualize the proportions to see just how skewed and disproportionate this dataset is. We include missing values to demonstrate their influence on the dataset as well. The chart below shows the distribution of all categorical variables, which includes the factors mentioned previously.\n\n\nCode\n# select categorical columns\ncat_cols = c()\nj <- 1\nfor (i in 1:ncol(loan_data)) {\n  if (class((loan_data[,i])) == 'factor') {\n      cat_cols[j]=names(loan_data[i])\n      j <- j+1\n  }\n}\n\nloan_fact <-  loan_data[cat_cols]\n# long format\nloan_factm <- melt(loan_fact, measure.vars = cat_cols, variable.name = 'metric', value.name = 'value')\n\n\nWarning: attributes are not identical across measure variables; they will be\ndropped\n\n\nCode\n# plot categorical columns\nggplot(loan_factm, aes(x = value)) + \n  geom_bar() + \n  scale_fill_brewer(palette = \"Set1\") + \n  facet_wrap( ~ metric, nrow = 5L, scales = 'free') + coord_flip()\n\n\n\n\n\nFrom this chart, it is very clear we have a dataset with mostly married male graduates with no dependents, a long credit history, and who are not self-employed. There is a relatively even mix of urban, suburban, and rural applicants and a small number of missing values. Applicants tend to be accepted more often than not and there are no missing observations for our target variable ‘Loan_Status’ nor the applicant’s property area or education. These are all of our categorical variables.\nWe also generate histograms with the count of each observation to assess our numeric variable distributions. This will let us know more about the skewness, average values, and where potential outliers may be found for our numeric variables. The graph below shows their distributions.\n\n\nCode\nplot_histogram(loan_data, geom_histogram_args = list(\"fill\" = \"tomato4\"))\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe applicant income and co-applicant income variables are highly right skewed with a smaller number of individual applicants stretching the distribution towards higher incomes. For analysis purposes, we must keep in mind that only a handful of applicants had higher incomes while the bulk of applicants were concentrated at the lower end of the income distribution. The loan amount term has one spike at 360. Meanwhile, the loan amount is the closest to normal. These results are consistent with our summary table.\nNext we will review the impact of the categorical variables’ proportions on loan approval in more detail by isolating the factor levels individually. Here again, we visualize the proportions as a bar chart without missing values and expand the size of the chart to see the nuances of each. These are placed alongside each variable’s frequency table by level to visualize their proportions. The results are as follows:\n\n\nCode\nloan_ch <- with(loan_data, table(Credit_History, Loan_Status)) %>% \n  prop.table(margin = 1) %>% as.data.frame() %>% filter(Loan_Status == 'Y')\n\nloan_ch\n\n\n\n\n  \n\n\n\n\n\nCode\nggplot(loan_ch, aes(x=Credit_History, y=Freq, fill=Credit_History)) + geom_bar(stat='identity') + labs(title = 'Approved Loans by Credit History', y = \"Percentage\", x = \"Credit History\")\n\n\n\n\n\n\n\nCode\nloan_gen <- with(loan_data, table(Gender, Loan_Status)) %>% \n  prop.table(margin = 1) %>% as.data.frame() %>% filter(Loan_Status == 'Y')\n\nloan_gen\n\n\n\n\n  \n\n\n\n\n\nCode\nggplot(loan_gen, aes(x=Gender, y=Freq, fill=Gender)) + geom_bar(stat='identity') + labs(title = 'Approved Loans by Gender', y = \"Percentage\", x = \"Gender\")\n\n\n\n\n\n\n\nCode\nloan_ed <- with(loan_data, table(Education, Loan_Status)) %>% \n  prop.table(margin = 1) %>% as.data.frame() %>% filter(Loan_Status == 'Y')\n\nloan_ed\n\n\n\n\n  \n\n\n\n\n\nCode\nggplot(loan_ed, aes(x=Education, y=Freq, fill=Education)) + geom_bar(stat='identity') + labs(title = 'Approved Loans by Education', y = \"Percentage\", x = \"Education\")\n\n\n\n\n\n\n\nCode\nloan_mar <- with(loan_data, table(Married, Loan_Status)) %>% \n  prop.table(margin = 1) %>% as.data.frame() %>% filter(Loan_Status == 'Y')\n\nloan_mar\n\n\n\n\n  \n\n\n\n\n\nCode\nggplot(loan_mar, aes(x=Married, y=Freq, fill=Married)) + geom_bar(stat='identity') + labs(title = 'Approved Loans by Married', y = \"Percentage\", x = \"Married\")\n\n\n\n\n\n\n\nCode\nloan_dep <- with(loan_data, table(Dependents, Loan_Status)) %>% \n  prop.table(margin = 1) %>% as.data.frame() %>% filter(Loan_Status == 'Y')\n\nloan_dep\n\n\n\n\n  \n\n\n\n\n\nCode\nggplot(loan_dep, aes(x=Dependents, y=Freq, fill=Dependents)) + geom_bar(stat='identity') + labs(title = 'Approved Loans by Dependents', y = \"Percentage\", x = \"Dependents\")\n\n\n\n\n\nThese bar charts confirm our thoughts about the dataset’s disproportionalities. Missing values have little effect on the overall proportions and so they can be removed. It remains male dominated with applicants who are married, have no dependents, are highly educated, and have a long credit history."
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#correlations",
    "href": "posts/Loan Assessment/LendingApproval.html#correlations",
    "title": "Loan Approval",
    "section": "Correlations",
    "text": "Correlations\nTo determine how well each variable is correlated with our target variable and with one another, we construct a correlation plot. This plot contains the values of all correlation between variables represented by colors and numbers. The row we review the most is our target variable, ‘Loan_Status.’\n\n\nCode\nG = cor(loan_data[6:(length(loan_data)-3)])\ncorrplot(G, method = 'number') # colorful number\n\n\n\n\n\nThe numeric features do not seem to be strongly correlated with another so that is a factor that does not have to be dealt with.\n\n\nCode\nG = cor(loan_data[6:(length(loan_data)-3)])\ncorrplot(G, method = 'number') # colorful number\n\n\n\n\n\nGiven that our numeric features have correlation values near 0, they do not seem to be strongly correlated with our target. They also do not seem to have any correlation with one another so this is a factor that does not have to be dealt with."
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#handling-missing-values",
    "href": "posts/Loan Assessment/LendingApproval.html#handling-missing-values",
    "title": "Loan Approval",
    "section": "Handling missing values",
    "text": "Handling missing values\n\n\nCode\n# plot missing values\nplot_missing(loan_data)\n\n\n\n\n\nWe can see above credit_history contributes to 8% of missing data along with self_employed that accounts for more than 5% of missing data. All records having missing categorical predictors will be removed. Next we will impute numeric values using MICE (Multivariate Imputation by Chained Equations).\n\n\nCode\n# Filter out the data which has missing categorical predictors\nloan_data <- loan_data %>% filter(!is.na(Credit_History) &\n                                  !is.na(Self_Employed) &  \n                                  !is.na(Dependents) & \n                                  !is.na(Gender) & \n                                  !is.na(Married))\n\n\n\n\nCode\n# impute numeric predictors using mice\nloan_data <- complete(mice(data=loan_data, method=\"pmm\", print=FALSE))\n\n\n\n\nCode\ndim(loan_data)\n\n\n[1] 511  12\n\n\nFinally our clean dataset contains 511 rows and 12 columns."
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#preprocess-using-transformation",
    "href": "posts/Loan Assessment/LendingApproval.html#preprocess-using-transformation",
    "title": "Loan Approval",
    "section": "Preprocess using transformation",
    "text": "Preprocess using transformation\nWe have seen above that numeric features are right skewed so in this step we will use caret preprocess method using box cox, center and scale transformation.\n\n\nCode\n# library(e1071) - where this was used\nset.seed(622)\nloan_data <- loan_data %>% \n  dplyr::select(c(\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\")) %>%\n  preProcess(method = c(\"BoxCox\",\"center\",\"scale\")) %>% \n  predict(loan_data)"
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#training-and-test-partition",
    "href": "posts/Loan Assessment/LendingApproval.html#training-and-test-partition",
    "title": "Loan Approval",
    "section": "Training and Test Partition",
    "text": "Training and Test Partition\nIn this step for data preparation we will partition the training dataset in training and validation sets using createDataPartition method from caret package. We will reserve 75% for training and rest 25% for validation purpose.\n\n\nCode\nset.seed(622)\npartition <- createDataPartition(loan_data$Loan_Status, p=0.75, list = FALSE)\n\ntraining <- loan_data[partition,]\ntesting <- loan_data[-partition,]\n\n# training/validation partition for independent variables\n#X.train <- ld.clean[partition, ] %>% dplyr::select(-Loan_Status)\n#X.test <- ld.clean[-partition, ] %>% dplyr::select(-Loan_Status)\n\n# training/validation partition for dependent variable Loan_Status\n#y.train <- ld.clean$Loan_Status[partition]\n#y.test <- ld.clean$Loan_Status[-partition]"
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#linear-discriminant-analysis-lda",
    "href": "posts/Loan Assessment/LendingApproval.html#linear-discriminant-analysis-lda",
    "title": "Loan Approval",
    "section": "Linear Discriminant Analysis (LDA)",
    "text": "Linear Discriminant Analysis (LDA)\n\n\nCode\n# LDA model\nlda_model <- lda(Loan_Status~., data = loan_data)\nlda_model\n\n\nCall:\nlda(Loan_Status ~ ., data = loan_data)\n\nPrior probabilities of groups:\n        N         Y \n0.3209393 0.6790607 \n\nGroup means:\n  GenderMale MarriedYes Dependents1 Dependents2 Dependents3+\nN  0.7926829  0.5792683   0.1829268   0.1341463   0.09756098\nY  0.8357349  0.6801153   0.1585014   0.1902017   0.08069164\n  EducationNot Graduate Self_EmployedYes ApplicantIncome CoapplicantIncome\nN             0.2682927        0.1463415     0.003576320         0.0571435\nY             0.1902017        0.1325648    -0.001690249        -0.0270073\n   LoanAmount Loan_Amount_Term Credit_History1 Property_AreaSemiurban\nN  0.07966414      0.016992352       0.5548780              0.2682927\nY -0.03765106     -0.008030968       0.9798271              0.4409222\n  Property_AreaUrban\nN          0.3719512\nY          0.2997118\n\nCoefficients of linear discriminants:\n                                LD1\nGenderMale              0.185159211\nMarriedYes              0.375755462\nDependents1            -0.209004726\nDependents2             0.137509542\nDependents3+            0.007142953\nEducationNot Graduate  -0.294391997\nSelf_EmployedYes       -0.025905262\nApplicantIncome        -0.012085555\nCoapplicantIncome      -0.106529320\nLoanAmount             -0.099136040\nLoan_Amount_Term       -0.049820158\nCredit_History1         3.073804026\nProperty_AreaSemiurban  0.616732100\nProperty_AreaUrban      0.066231320\n\n\n\n\nCode\n# prediction from lda model\nlda_predict <- lda_model %>% \n  predict(testing)\n\n\n\n\nCode\n# accuracy\nmean(lda_predict$class==testing$Loan_Status)\n\n\n[1] 0.8110236\n\n\nCode\nconfusionMatrix(lda_predict$class, testing$Loan_Status)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  N  Y\n         N 19  2\n         Y 22 84\n                                        \n               Accuracy : 0.811         \n                 95% CI : (0.732, 0.875)\n    No Information Rate : 0.6772        \n    P-Value [Acc > NIR] : 0.0005479     \n                                        \n                  Kappa : 0.5046        \n                                        \n Mcnemar's Test P-Value : 0.0001052     \n                                        \n            Sensitivity : 0.4634        \n            Specificity : 0.9767        \n         Pos Pred Value : 0.9048        \n         Neg Pred Value : 0.7925        \n             Prevalence : 0.3228        \n         Detection Rate : 0.1496        \n   Detection Prevalence : 0.1654        \n      Balanced Accuracy : 0.7201        \n                                        \n       'Positive' Class : N             \n                                        \n\n\nLDA model accuracy comes out as ~81%"
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#k-nearest-neighbor-knn",
    "href": "posts/Loan Assessment/LendingApproval.html#k-nearest-neighbor-knn",
    "title": "Loan Approval",
    "section": "K-nearest neighbor (KNN)",
    "text": "K-nearest neighbor (KNN)\n\n\nCode\n# KNN model\nset.seed(622)\ntrain.knn <- training[, names(training) != \"Direction\"]\nprep <- preProcess(x = train.knn, method = c(\"center\", \"scale\"))\nprep\n\n\nCreated from 384 samples and 12 variables\n\nPre-processing:\n  - centered (4)\n  - ignored (8)\n  - scaled (4)\n\n\nCode\ncl <- trainControl(method=\"repeatedcv\", repeats = 5) \nknn_model <- train(Loan_Status ~ ., data = training, \n                method = \"knn\", \n                trControl = cl, \n                preProcess = c(\"center\",\"scale\"), \n                tuneLength = 20)\nknn_model \n\n\nk-Nearest Neighbors \n\n384 samples\n 11 predictor\n  2 classes: 'N', 'Y' \n\nPre-processing: centered (14), scaled (14) \nResampling: Cross-Validated (10 fold, repeated 5 times) \nSummary of sample sizes: 346, 346, 346, 345, 346, 345, ... \nResampling results across tuning parameters:\n\n  k   Accuracy   Kappa    \n   5  0.7590209  0.3575145\n   7  0.7689406  0.3751117\n   9  0.7725985  0.3746036\n  11  0.7782524  0.3884713\n  13  0.7829615  0.3994494\n  15  0.7787908  0.3849571\n  17  0.7689528  0.3503238\n  19  0.7642294  0.3309567\n  21  0.7647551  0.3299468\n  23  0.7548097  0.2947001\n  25  0.7454298  0.2607665\n  27  0.7412733  0.2448000\n  29  0.7402746  0.2423939\n  31  0.7365911  0.2319391\n  33  0.7292901  0.2050164\n  35  0.7251066  0.1885755\n  37  0.7178596  0.1615955\n  39  0.7126768  0.1383143\n  41  0.7100317  0.1282468\n  43  0.7084798  0.1212857\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 13.\n\n\n\n\nCode\n# prediction from knn model\nplot(knn_model)\n\n\n\n\n\nCode\nknn_predict <- predict(knn_model,newdata = testing)\nmean(knn_predict == testing$Loan_Status) # accuracy\n\n\n[1] 0.7952756\n\n\nCode\nconfusionMatrix(knn_predict, testing$Loan_Status)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  N  Y\n         N 17  2\n         Y 24 84\n                                          \n               Accuracy : 0.7953          \n                 95% CI : (0.7146, 0.8617)\n    No Information Rate : 0.6772          \n    P-Value [Acc > NIR] : 0.002202        \n                                          \n                  Kappa : 0.4553          \n                                          \n Mcnemar's Test P-Value : 3.814e-05       \n                                          \n            Sensitivity : 0.4146          \n            Specificity : 0.9767          \n         Pos Pred Value : 0.8947          \n         Neg Pred Value : 0.7778          \n             Prevalence : 0.3228          \n         Detection Rate : 0.1339          \n   Detection Prevalence : 0.1496          \n      Balanced Accuracy : 0.6957          \n                                          \n       'Positive' Class : N               \n                                          \n\n\nKNN model accuracy comes out as ~80%"
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#decision-trees",
    "href": "posts/Loan Assessment/LendingApproval.html#decision-trees",
    "title": "Loan Approval",
    "section": "Decision Trees",
    "text": "Decision Trees\n\n\nCode\n# Decision Trees model\nset.seed(622)\ntree.loans = tree(Loan_Status~., data=training)\nsummary(tree.loans)\n\n\n\nClassification tree:\ntree(formula = Loan_Status ~ ., data = training)\nVariables actually used in tree construction:\n[1] \"Credit_History\"    \"Property_Area\"     \"CoapplicantIncome\"\nNumber of terminal nodes:  5 \nResidual mean deviance:  0.921 = 349 / 379 \nMisclassification error rate: 0.1849 = 71 / 384 \n\n\nCode\nplot(tree.loans)\ntext(tree.loans, pretty = 0)\n\n\n\n\n\n\n\nCode\n# prediction from decision tree model\ntree.predict<-predict(tree.loans, testing, type = 'class')\nmean(tree.predict == testing$Loan_Status) # accuracy\n\n\n[1] 0.7952756\n\n\nCode\nconfusionMatrix(tree.predict, testing$Loan_Status)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  N  Y\n         N 19  4\n         Y 22 82\n                                          \n               Accuracy : 0.7953          \n                 95% CI : (0.7146, 0.8617)\n    No Information Rate : 0.6772          \n    P-Value [Acc > NIR] : 0.0022025       \n                                          \n                  Kappa : 0.471           \n                                          \n Mcnemar's Test P-Value : 0.0008561       \n                                          \n            Sensitivity : 0.4634          \n            Specificity : 0.9535          \n         Pos Pred Value : 0.8261          \n         Neg Pred Value : 0.7885          \n             Prevalence : 0.3228          \n         Detection Rate : 0.1496          \n   Detection Prevalence : 0.1811          \n      Balanced Accuracy : 0.7085          \n                                          \n       'Positive' Class : N               \n                                          \n\n\nDecision Tree model accuracy comes out as ~80%"
  },
  {
    "objectID": "posts/Loan Assessment/LendingApproval.html#random-forests",
    "href": "posts/Loan Assessment/LendingApproval.html#random-forests",
    "title": "Loan Approval",
    "section": "Random Forests",
    "text": "Random Forests\n\n\nCode\nset.seed(622)\n# Random Forest model\nrf.loans <- randomForest(Loan_Status~., data = training)\nrf.loans\n\n\n\nCall:\n randomForest(formula = Loan_Status ~ ., data = training) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n        OOB estimate of  error rate: 20.57%\nConfusion matrix:\n   N   Y class.error\nN 59  64  0.52032520\nY 15 246  0.05747126\n\n\n\n\nCode\n# prediction from random forest model\nrf.predict <- predict(rf.loans, testing,type='class')\nmean(rf.predict == testing$Loan_Status) # accuracy\n\n\n[1] 0.8110236\n\n\nCode\nconfusionMatrix(rf.predict, testing$Loan_Status)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  N  Y\n         N 22  5\n         Y 19 81\n                                        \n               Accuracy : 0.811         \n                 95% CI : (0.732, 0.875)\n    No Information Rate : 0.6772        \n    P-Value [Acc > NIR] : 0.0005479     \n                                        \n                  Kappa : 0.5254        \n                                        \n Mcnemar's Test P-Value : 0.0079635     \n                                        \n            Sensitivity : 0.5366        \n            Specificity : 0.9419        \n         Pos Pred Value : 0.8148        \n         Neg Pred Value : 0.8100        \n             Prevalence : 0.3228        \n         Detection Rate : 0.1732        \n   Detection Prevalence : 0.2126        \n      Balanced Accuracy : 0.7392        \n                                        \n       'Positive' Class : N             \n                                        \n\n\nRandom Forest model accuracy comes out as ~80%"
  },
  {
    "objectID": "posts/Stock Prediction/arima.html",
    "href": "posts/Stock Prediction/arima.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "A good forecast is a blessing while the wrong forecast could prove to be dangerous"
  },
  {
    "objectID": "posts/Stock Prediction/arima.html#introduction",
    "href": "posts/Stock Prediction/arima.html#introduction",
    "title": "Time Series Analysis",
    "section": "Introduction",
    "text": "Introduction\nGiven an unknown data source with several groups, we attempt to predict the next 140 values of a times series data set based on 1622 entries provided on multiple events. Our predictions will be fine-tuned to reduce the mean absolute percentage error (MAPE) as much as possible. The packages we will be using and all associated code to produce the models can be found in the attached markdown file. The data with its first five rows, are shown below.\n\n\nCode\n# Data source\ndata <- read.csv(\"https://raw.githubusercontent.com/palmorezm/msds/main/Predictive%20Analytics/Projects/Project1/project1data.csv\")\n# data <- data %>% \n#   rename(SeriesInd = ï..SeriesInd) \nhead(data, 5)\n\n\n\n\n  \n\n\n\nWe create forecasts for two preselected variables within each of six predetermined groups. These groups are denoted S01, S02, S03, S04, S05, and S06 respectively. There are five variables within each group that we have to work with. They are Var01, Var02, Var03, Var05, and Var07 respectively. Our date variable ‘SeriesInd,’ is displayed in its numeric serial number form calculated with Excel. Although we do not know what the variables stand for, we can develop models to try and forecast their behavior. This chart contains a breakdown of which variables are forecast in each group.\n\n\nCode\n# Chart\nvarsbygroup <- data.frame(matrix(c(\"S01\", \"S02\", \"S03\",\n                                   \"S04\", \"S05\", \"S06\", \n                                   \"Var01\", \"Var02\", \"Var05\",\n                                   \"Var01\", \"Var02\", \"Var05\",\n                                   \"Var02\", \"Var03\", \"Var07\",\n                                   \"Var02\", \"Var03\", \"Var07\"),\n                                 nrow = 6, ncol=3))\ncolnames(varsbygroup) <- c(\"Group\", \"Variable1\", \"Variable2\")\nvarsbygroup %>% \n  kbl(booktabs = T) %>% \n  kable_styling(latex_options = c(\"striped\", \"HOLD_position\", \"scale_down\"), full_width = T)\n\n\n\n\n \n  \n    Group \n    Variable1 \n    Variable2 \n  \n \n\n  \n    S01 \n    Var01 \n    Var02 \n  \n  \n    S02 \n    Var02 \n    Var03 \n  \n  \n    S03 \n    Var05 \n    Var07 \n  \n  \n    S04 \n    Var01 \n    Var02 \n  \n  \n    S05 \n    Var02 \n    Var03 \n  \n  \n    S06 \n    Var05 \n    Var07 \n  \n\n\n\n\n\nCode\n# Grouping\nS01 <- data %>% \n  filter(group == \"S01\")\nS02 <- data %>% \n  filter(group == \"S02\")\nS03 <- data %>% \n  filter(group == \"S03\")\nS04 <- data %>% \n  filter(group == \"S04\")\nS05 <- data %>% \n  filter(group == \"S05\")\nS06 <- data %>% \n  filter(group == \"S06\")\n\n# Imputation by function - missing something? lapply/sapply may work \nsoximp <- function(df){\n  for (i in colnames(df)){\n    if (sum(is.na(df[[i]])) !=0){\n      df[[i]][is.na(df[[i]])] <- median(df[[i]], na.rm=TRUE)\n    }\n  }\n}\n\n# Imputation loops for each group by median \nfor (i in colnames(S01)){\n  if (sum(is.na(S01[[i]])) != 0){\n    S01[[i]][is.na(S01[[i]])] <- median(S01[[i]], na.rm = TRUE)\n  } \n}\nfor (i in colnames(S02)){\n  if (sum(is.na(S02[[i]])) != 0){\n    S02[[i]][is.na(S02[[i]])] <- median(S02[[i]], na.rm = TRUE)\n  } \n}\nfor (i in colnames(S03)){\n  if (sum(is.na(S03[[i]])) != 0){\n    S03[[i]][is.na(S03[[i]])] <- median(S03[[i]], na.rm = TRUE)\n  } \n}\nfor (i in colnames(S04)){\n  if (sum(is.na(S04[[i]])) != 0){\n    S04[[i]][is.na(S04[[i]])] <- median(S04[[i]], na.rm = TRUE)\n  } \n}\nfor (i in colnames(S05)){\n  if (sum(is.na(S05[[i]])) != 0){\n    S05[[i]][is.na(S05[[i]])] <- median(S05[[i]], na.rm = TRUE)\n  } \n}\nfor (i in colnames(S06)){\n  if (sum(is.na(S06[[i]])) != 0){\n    S06[[i]][is.na(S06[[i]])] <- median(S06[[i]], na.rm = TRUE)\n  } \n}\n\n\nBefore we begin, the data is filtered to extract each time series by group. This isolates the Var01, Var02, Var03, Var05, and Var07 variables associated with groups S01, S02, and so on. Then, with each group and its respective variables’ behavior isolated, we clean and adjust the data to make use of it in the analysis. Once we determine the most appropriate models to forecast the proper variable in each group, we evaluate the results of our predictions. Our final forecasts are captured in the excel spreadsheet attached."
  },
  {
    "objectID": "posts/Stock Prediction/arima.html#analysis",
    "href": "posts/Stock Prediction/arima.html#analysis",
    "title": "Time Series Analysis",
    "section": "Analysis",
    "text": "Analysis\nWe began by addressing missing values. Given 10,572 observations, about 8% of each variable was missing. Several methods were tried to address this but the best were Kalman smoothing and simple imputation by the median of each ‘Var0X’ variable to fill in where appropriate. The ‘SeriesInd’ numeric date was also converted from its serial number form to a common date-time series. We then examined each group’s variables separately.\n\n\nCode\n# library(fpp2)\n\n#S01\nS01<-subset(data, group == \"S01\", select = c(SeriesInd, Var01, Var02))%>%\n  mutate(date=as.Date(SeriesInd, origin = \"1905-01-01\"))\nsummary(S01)\n\n\n   SeriesInd         Var01           Var02               date           \n Min.   :40669   Min.   :23.01   Min.   : 1339900   Min.   :2016-05-07  \n 1st Qu.:41304   1st Qu.:29.85   1st Qu.: 5347550   1st Qu.:2018-01-31  \n Median :41946   Median :35.66   Median : 7895050   Median :2019-11-05  \n Mean   :41945   Mean   :39.41   Mean   : 8907092   Mean   :2019-11-03  \n 3rd Qu.:42586   3rd Qu.:48.70   3rd Qu.:11321675   3rd Qu.:2021-08-06  \n Max.   :43221   Max.   :62.31   Max.   :48477500   Max.   :2023-05-03  \n                 NA's   :142     NA's   :140                            \n\n\nCode\n# Subset Var01 and Var02 from S01.\nS01_Var01<-S01 %>%select(Var01)\nS01_Var01<-S01_Var01[1:1625,]\n\n\nS01_Var02<-S01 %>%select(Var02)\nS01_Var02<-S01_Var02[1:1625,]\n\n\n#S02\nS02<-subset(data, group == \"S02\", select = c(SeriesInd, Var02, Var03))%>%\n  mutate(date=as.Date(SeriesInd, origin = \"1905-01-01\"))\nsummary(S02)\n\n\n   SeriesInd         Var02               Var03            date           \n Min.   :40669   Min.   :  7128800   Min.   : 8.82   Min.   :2016-05-07  \n 1st Qu.:41304   1st Qu.: 27880300   1st Qu.:11.82   1st Qu.:2018-01-31  \n Median :41946   Median : 39767500   Median :13.76   Median :2019-11-05  \n Mean   :41945   Mean   : 50633098   Mean   :13.68   Mean   :2019-11-03  \n 3rd Qu.:42586   3rd Qu.: 59050900   3rd Qu.:15.52   3rd Qu.:2021-08-06  \n Max.   :43221   Max.   :480879500   Max.   :38.28   Max.   :2023-05-03  \n                 NA's   :140         NA's   :144                         \n\n\nCode\n# Subset Var02 and Var03 from S02.\nS02_Var02<-S02 %>%select(Var02)\nS02_Var02<-S02_Var02[1:1625,]\n\n\nS02_Var03<-S02 %>%select(Var03)\nS02_Var03<-S02_Var03[1:1625,]\n\n\n\n#S03\nS03<-subset(data, group == \"S03\", select = c(SeriesInd, Var05, Var07))%>%\n  mutate(date=as.Date(SeriesInd, origin = \"1905-01-01\"))\nsummary(S03)\n\n\n   SeriesInd         Var05            Var07             date           \n Min.   :40669   Min.   : 27.48   Min.   : 27.44   Min.   :2016-05-07  \n 1st Qu.:41304   1st Qu.: 53.30   1st Qu.: 53.46   1st Qu.:2018-01-31  \n Median :41946   Median : 75.59   Median : 75.71   Median :2019-11-05  \n Mean   :41945   Mean   : 76.90   Mean   : 76.87   Mean   :2019-11-03  \n 3rd Qu.:42586   3rd Qu.: 98.55   3rd Qu.: 98.61   3rd Qu.:2021-08-06  \n Max.   :43221   Max.   :134.46   Max.   :133.00   Max.   :2023-05-03  \n                 NA's   :144      NA's   :144                          \n\n\nCode\n# Subset Var05 and Var07 from S03.\nS03_Var05<-S03 %>%select(Var05)\nS03_Var05<-S03_Var05[1:1625,]\n\n\nS03_Var07<-S03 %>%select(Var07)\nS03_Var07<-S03_Var07[1:1625,]\n\n\nStatistical summaries, box plots, and histograms were run on each group to evaluate where the average value of each variable was, if its distribution was skewed, determine whether outliers were present, and provide other descriptors of the data. These informed us that the average value (mean) of the variables are similar but their range varies widely with Var05 at 186.01 while Var02 covers a range of 479 million. Our analysis solves this potential problem by focusing on variables of the same scales as the intended target.\n\n\nCode\nsummary(S01_Var01)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.01   29.85   35.72   39.47   48.76   62.38 \n\n\nCode\npar(mfrow = c(1,2))\nhist(ts_S01_Var01)\nboxplot(ts_S01_Var01)\n\n\n\n\n\nCode\nautoplot(ts_S01_Var01)\n\n\n\n\n\nAdditionally, all but group S03 of the histograms exhibited right skewness, and Var02 and Var03 had outliers. These were replaced using Friedman’s super smoothing method. Due to the randomness of these variables, determining outliers was difficult and there is a presence of additional overly influential points as determined using Cook’s distance formula. We acknowledge the presence of these points but are unable to alter them as they are likely intentional based on the patterns in the data. For reference, the observations are shown in the scatter plot with color coding by each group.\n\n\nCode\ndata[c(1:7)]%>%\n  gather(variable, value, -SeriesInd, -group) %>%\n  ggplot(., aes(value, SeriesInd, color = group)) + \n  geom_point(fill = \"white\",\n             size=1, \n             shape=21, \n             alpha = 0.75) + \n  coord_flip() + \n   facet_wrap(~variable, \n             scales =\"free\") + \n  labs(title = \"Variable Patterns\", \n       subtitle = \"Color Coded by Group\", \n       x=\"Value\", \n       y=\"Time\", \n       caption = \"Contains all non-null observations of the given data set\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust=0.5), \n        plot.subtitle = element_text(hjust=0.5),\n        legend.position = \"bottom\", \n        axis.ticks.x=element_blank(),\n        axis.text.x=element_blank(), \n        plot.caption = element_text(hjust=0.5)\n        )\n\n\n\n\n\nSeasonality was also considered. It is possible this data follows a weak seasonal trend that increases during summer months but there is not a lot of evidence to support regular fluctuations. Regular gaps were noticed in the time series on a weekly basis and several methods were used in attempts to fix this. However, the data appears randomly distributed and as such, acts randomly. For this reason, we left the gaps alone and any further adjustments made were minimal to avoid disturbing any existing patterns in the data.\nWe determined that the best model type was an Auto Regressive Integrated Moving Average (ARIMA) with drift. Unfortunately, all variables required differencing to achieve stationarity. This indicates that any predictions made with these variables may be unrealistic because of inherent random changes in statistics like the mean and variance of these variables over time. We transform the data in our attempts to achieve stationarity but it should be noted that our review of stationarity is only a rough estimate using the aforementioned summary statistics so that we may apply this ARIMA method. Otherwise, we would have to conclude this data is inherently unpredictable and as such, render model forecasts useless. Rather, we focus on forecasting each variable individually and try to keep it simple."
  },
  {
    "objectID": "posts/Stock Prediction/arima.html#prediction",
    "href": "posts/Stock Prediction/arima.html#prediction",
    "title": "Time Series Analysis",
    "section": "Prediction",
    "text": "Prediction\n\n\nCode\nmape0101\n\n\n[1] 5.7693\n\n\nCode\nfcast0101\n\n\n     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\n1626       62.39704 61.74274 63.05135 61.39637 63.39772\n1627       62.41922 61.45258 63.38587 60.94086 63.89758\n1628       62.44125 61.26868 63.61382 60.64795 64.23454\n1629       62.46327 61.11589 63.81065 60.40263 64.52392\n1630       62.48530 60.98331 63.98728 60.18821 64.78238\n1631       62.50732 60.86523 64.14942 59.99596 65.01869\n1632       62.52935 60.75819 64.30050 59.82060 65.23809\n1633       62.55137 60.65994 64.44280 59.65868 65.44406\n1634       62.57340 60.56890 64.57790 59.50778 65.63901\n1635       62.59542 60.48390 64.70695 59.36612 65.82472\n1636       62.61745 60.40407 64.83083 59.23237 66.00252\n1637       62.63947 60.32872 64.95022 59.10548 66.17346\n1638       62.66150 60.25732 65.06568 58.98462 66.33837\n1639       62.68352 60.18941 65.17763 58.86910 66.49794\n1640       62.70555 60.12463 65.28646 58.75838 66.65271\n1641       62.72757 60.06268 65.39246 58.65198 66.80317\n1642       62.74960 60.00330 65.49589 58.54950 66.94969\n1643       62.77162 59.94626 65.59698 58.45060 67.09264\n1644       62.79364 59.89137 65.69592 58.35500 67.23229\n1645       62.81567 59.83847 65.79286 58.26244 67.36890\n1646       62.83769 59.78741 65.88797 58.17269 67.50270\n1647       62.85972 59.73806 65.98137 58.08556 67.63388\n1648       62.88174 59.69031 66.07318 58.00087 67.76262\n1649       62.90377 59.64405 66.16349 57.91846 67.88908\n1650       62.92579 59.59919 66.25239 57.83820 68.01339\n1651       62.94782 59.55565 66.33998 57.75995 68.13569\n1652       62.96984 59.51336 66.42633 57.68360 68.25608\n1653       62.99187 59.47223 66.51150 57.60905 68.37468\n1654       63.01389 59.43223 66.59556 57.53621 68.49158\n1655       63.03592 59.39327 66.67856 57.46498 68.60686\n1656       63.05794 59.35533 66.76056 57.39528 68.72061\n1657       63.07997 59.31833 66.84160 57.32705 68.83289\n1658       63.10199 59.28225 66.92173 57.26021 68.94378\n1659       63.12402 59.24704 67.00099 57.19470 69.05333\n1660       63.14604 59.21267 67.07942 57.13047 69.16162\n1661       63.16807 59.17909 67.15704 57.06745 69.26868\n1662       63.19009 59.14627 67.23391 57.00561 69.37458\n1663       63.21212 59.11419 67.31004 56.94488 69.47935\n1664       63.23414 59.08282 67.38547 56.88524 69.58304\n1665       63.25617 59.05212 67.46021 56.82663 69.68570\n1666       63.27819 59.02207 67.53431 56.76902 69.78736\n1667       63.30022 58.99266 67.60777 56.71238 69.88805\n1668       63.32224 58.96385 67.68063 56.65666 69.98782\n1669       63.34426 58.93563 67.75290 56.60184 70.08669\n1670       63.36629 58.90797 67.82461 56.54788 70.18470\n1671       63.38831 58.88086 67.89576 56.49476 70.28186\n1672       63.41034 58.85429 67.96639 56.44246 70.37822\n1673       63.43236 58.82822 68.03651 56.39093 70.47379\n1674       63.45439 58.80265 68.10613 56.34017 70.56861\n1675       63.47641 58.77757 68.17526 56.29015 70.66268\n1676       63.49844 58.75295 68.24393 56.24084 70.75604\n1677       63.52046 58.72878 68.31214 56.19222 70.84871\n1678       63.54249 58.70506 68.37992 56.14428 70.94070\n1679       63.56451 58.68176 68.44726 56.09699 71.03203\n1680       63.58654 58.65889 68.51419 56.05035 71.12273\n1681       63.60856 58.63641 68.58071 56.00432 71.21281\n1682       63.63059 58.61434 68.64684 55.95889 71.30228\n1683       63.65261 58.59264 68.71258 55.91406 71.39117\n1684       63.67464 58.57132 68.77795 55.86979 71.47948\n1685       63.69666 58.55037 68.84295 55.82609 71.56724\n1686       63.71869 58.52977 68.90760 55.78293 71.65445\n1687       63.74071 58.50952 68.97190 55.74030 71.74113\n1688       63.76274 58.48961 69.03586 55.69818 71.82729\n1689       63.78476 58.47003 69.09949 55.65658 71.91294\n1690       63.80679 58.45077 69.16280 55.61547 71.99811\n1691       63.82881 58.43183 69.22579 55.57484 72.08278\n1692       63.85084 58.41319 69.28848 55.53468 72.16699\n1693       63.87286 58.39486 69.35086 55.49499 72.25073\n1694       63.89489 58.37683 69.41294 55.45574 72.33403\n1695       63.91691 58.35908 69.47474 55.41694 72.41688\n1696       63.93893 58.34161 69.53626 55.37857 72.49930\n1697       63.96096 58.32443 69.59749 55.34062 72.58129\n1698       63.98298 58.30751 69.65846 55.30309 72.66288\n1699       64.00501 58.29086 69.71916 55.26597 72.74405\n1700       64.02703 58.27446 69.77960 55.22924 72.82483\n1701       64.04906 58.25833 69.83979 55.19290 72.90522\n1702       64.07108 58.24244 69.89973 55.15694 72.98523\n1703       64.09311 58.22680 69.95942 55.12136 73.06486\n1704       64.11513 58.21139 70.01887 55.08614 73.14412\n1705       64.13716 58.19623 70.07809 55.05129 73.22303\n1706       64.15918 58.18129 70.13707 55.01679 73.30158\n1707       64.18121 58.16659 70.19583 54.98264 73.37978\n1708       64.20323 58.15210 70.25436 54.94883 73.45764\n1709       64.22526 58.13784 70.31268 54.91535 73.53517\n1710       64.24728 58.12378 70.37078 54.88220 73.61236\n1711       64.26931 58.10995 70.42867 54.84938 73.68924\n1712       64.29133 58.09631 70.48635 54.81687 73.76580\n1713       64.31336 58.08289 70.54383 54.78467 73.84204\n1714       64.33538 58.06966 70.60110 54.75278 73.91798\n1715       64.35741 58.05663 70.65818 54.72120 73.99361\n1716       64.37943 58.04379 70.71507 54.68991 74.06895\n1717       64.40146 58.03115 70.77176 54.65891 74.14400\n1718       64.42348 58.01869 70.82827 54.62820 74.21876\n1719       64.44551 58.00642 70.88459 54.59777 74.29324\n1720       64.46753 57.99433 70.94074 54.56762 74.36744\n1721       64.48956 57.98241 70.99670 54.53774 74.44137\n1722       64.51158 57.97068 71.05248 54.50813 74.51503\n1723       64.53360 57.95911 71.10810 54.47879 74.58842\n1724       64.55563 57.94772 71.16354 54.44971 74.66155\n1725       64.57765 57.93650 71.21881 54.42088 74.73443\n1726       64.59968 57.92544 71.27392 54.39231 74.80705\n1727       64.62170 57.91454 71.32886 54.36399 74.87942\n1728       64.64373 57.90381 71.38365 54.33591 74.95155\n1729       64.66575 57.89323 71.43827 54.30808 75.02343\n1730       64.68778 57.88281 71.49274 54.28048 75.09507\n1731       64.70980 57.87255 71.54706 54.25312 75.16648\n1732       64.73183 57.86243 71.60122 54.22600 75.23766\n1733       64.75385 57.85247 71.65524 54.19910 75.30861\n1734       64.77588 57.84265 71.70910 54.17243 75.37933\n1735       64.79790 57.83298 71.76282 54.14598 75.44983\n1736       64.81993 57.82345 71.81640 54.11975 75.52011\n1737       64.84195 57.81407 71.86984 54.09373 75.59017\n1738       64.86398 57.80482 71.92313 54.06793 75.66002\n1739       64.88600 57.79571 71.97629 54.04234 75.72966\n1740       64.90803 57.78674 72.02931 54.01696 75.79909\n1741       64.93005 57.77790 72.08220 53.99179 75.86832\n1742       64.95208 57.76920 72.13495 53.96681 75.93734\n1743       64.97410 57.76062 72.18758 53.94204 76.00616\n1744       64.99613 57.75218 72.24007 53.91747 76.07479\n1745       65.01815 57.74386 72.29244 53.89309 76.14322\n1746       65.04018 57.73567 72.34468 53.86890 76.21145\n1747       65.06220 57.72760 72.39680 53.84490 76.27950\n1748       65.08423 57.71966 72.44879 53.82109 76.34736\n1749       65.10625 57.71184 72.50066 53.79747 76.41503\n1750       65.12827 57.70413 72.55242 53.77403 76.48252\n1751       65.15030 57.69655 72.60405 53.75077 76.54982\n1752       65.17232 57.68908 72.65557 53.72770 76.61695\n1753       65.19435 57.68173 72.70697 53.70479 76.68390\n1754       65.21637 57.67450 72.75825 53.68207 76.75068\n1755       65.23840 57.66737 72.80943 53.65951 76.81728\n1756       65.26042 57.66036 72.86049 53.63713 76.88372\n1757       65.28245 57.65346 72.91144 53.61492 76.94998\n1758       65.30447 57.64667 72.96228 53.59287 77.01608\n1759       65.32650 57.63998 73.01301 53.57099 77.08201\n1760       65.34852 57.63341 73.06364 53.54927 77.14777\n1761       65.37055 57.62694 73.11416 53.52771 77.21338\n1762       65.39257 57.62057 73.16458 53.50632 77.27883\n1763       65.41460 57.61430 73.21489 53.48508 77.34412\n1764       65.43662 57.60814 73.26510 53.46400 77.40925\n1765       65.45865 57.60208 73.31521 53.44307 77.47422\n\n\nCode\n# fcast0101 %>% \n#   ggplot(aes(x = Lo95, y =))"
  }
]